{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 434,
      "metadata": {
        "id": "J1q_qKIV2t2u"
      },
      "outputs": [],
      "source": [
        "#Import all library needed\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization, Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "#confusion matrix visualization\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix,classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 435,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "WazdlOZefP88",
        "outputId": "35a851ac-94c6-4882-81d5-479a2a203715"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"heart.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 436,
      "metadata": {
        "id": "dZADep6q2t3D"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
              "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
              "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
              "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
              "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
              "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
              "\n",
              "   ca  thal  target  \n",
              "0   0     1       1  \n",
              "1   0     2       1  \n",
              "2   0     2       1  \n",
              "3   0     2       1  \n",
              "4   0     2       1  "
            ]
          },
          "execution_count": 436,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 3. Insert Exploratory data analysis (EDA) steps to analyze and investigate datasets.\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 437,
      "metadata": {
        "id": "61ylkru32t27"
      },
      "outputs": [],
      "source": [
        "### 4. What is the purpose of the code that sets a list of categorical variables\n",
        "### in a dataset and then casts those variables to the object data type using the astype() function?\n",
        "\n",
        "catagorialList = ['sex','cp','fbs','restecg','exang','ca','thal']\n",
        "for item in catagorialList:\n",
        "    data[item] = data[item].astype('object') #casting to object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 438,
      "metadata": {
        "id": "iNbqP4z32t3L"
      },
      "outputs": [],
      "source": [
        " ### 5. Create more data by categorical variable into indicator variables using 'get_dummies' function\n",
        "\n",
        "data = pd.get_dummies(data, drop_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 439,
      "metadata": {
        "id": "QhlOEgqg2t3i"
      },
      "outputs": [],
      "source": [
        "### 6. Explain line 3,4 and 5 and print the shape of x and y\n",
        "\n",
        "y = data['target'].values\n",
        "y = y.reshape(y.shape[0],1)\n",
        "x = data.drop(['target'],axis=1)\n",
        "##"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 440,
      "metadata": {
        "id": "rEGdOBJu2t3o"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.030100</td>\n",
              "      <td>0.331104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.003344</td>\n",
              "      <td>0.063545</td>\n",
              "      <td>0.665552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.006689</td>\n",
              "      <td>0.063545</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          a         b         c\n",
              "0  0.000000  0.030100  0.331104\n",
              "1  0.003344  0.063545  0.665552\n",
              "2  0.006689  0.063545  1.000000"
            ]
          },
          "execution_count": 440,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 7. Create a simple dataset and demonstrate the normalization code on the simple dataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "d = pd.DataFrame({\n",
        "    'a': [10, 20, 30],\n",
        "    'b': [100, 200, 200],\n",
        "    'c': [1000, 2000, 3000]\n",
        "})\n",
        "minx = np.min(d)\n",
        "maxx = np.max(d)\n",
        "d = (d - minx) / (maxx - minx)\n",
        "d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 441,
      "metadata": {
        "id": "asoFBQaumuKA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>thalach</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>sex_1</th>\n",
              "      <th>cp_1</th>\n",
              "      <th>cp_2</th>\n",
              "      <th>cp_3</th>\n",
              "      <th>...</th>\n",
              "      <th>restecg_1</th>\n",
              "      <th>restecg_2</th>\n",
              "      <th>exang_1</th>\n",
              "      <th>ca_1</th>\n",
              "      <th>ca_2</th>\n",
              "      <th>ca_3</th>\n",
              "      <th>ca_4</th>\n",
              "      <th>thal_1</th>\n",
              "      <th>thal_2</th>\n",
              "      <th>thal_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.111702</td>\n",
              "      <td>0.257092</td>\n",
              "      <td>0.413121</td>\n",
              "      <td>0.265957</td>\n",
              "      <td>0.004078</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.065603</td>\n",
              "      <td>0.230496</td>\n",
              "      <td>0.443262</td>\n",
              "      <td>0.331560</td>\n",
              "      <td>0.006206</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.072695</td>\n",
              "      <td>0.230496</td>\n",
              "      <td>0.361702</td>\n",
              "      <td>0.304965</td>\n",
              "      <td>0.002482</td>\n",
              "      <td>0.003546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.099291</td>\n",
              "      <td>0.212766</td>\n",
              "      <td>0.418440</td>\n",
              "      <td>0.315603</td>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.003546</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.101064</td>\n",
              "      <td>0.212766</td>\n",
              "      <td>0.627660</td>\n",
              "      <td>0.289007</td>\n",
              "      <td>0.001064</td>\n",
              "      <td>0.003546</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001773</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 21 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        age  trestbps      chol   thalach   oldpeak     slope     sex_1  \\\n",
              "0  0.111702  0.257092  0.413121  0.265957  0.004078  0.000000  0.001773   \n",
              "1  0.065603  0.230496  0.443262  0.331560  0.006206  0.000000  0.001773   \n",
              "2  0.072695  0.230496  0.361702  0.304965  0.002482  0.003546  0.000000   \n",
              "3  0.099291  0.212766  0.418440  0.315603  0.001418  0.003546  0.001773   \n",
              "4  0.101064  0.212766  0.627660  0.289007  0.001064  0.003546  0.000000   \n",
              "\n",
              "       cp_1      cp_2      cp_3  ...  restecg_1  restecg_2   exang_1  ca_1  \\\n",
              "0  0.000000  0.000000  0.001773  ...   0.000000        0.0  0.000000   0.0   \n",
              "1  0.000000  0.001773  0.000000  ...   0.001773        0.0  0.000000   0.0   \n",
              "2  0.001773  0.000000  0.000000  ...   0.000000        0.0  0.000000   0.0   \n",
              "3  0.001773  0.000000  0.000000  ...   0.001773        0.0  0.000000   0.0   \n",
              "4  0.000000  0.000000  0.000000  ...   0.001773        0.0  0.001773   0.0   \n",
              "\n",
              "   ca_2  ca_3  ca_4    thal_1    thal_2  thal_3  \n",
              "0   0.0   0.0   0.0  0.001773  0.000000     0.0  \n",
              "1   0.0   0.0   0.0  0.000000  0.001773     0.0  \n",
              "2   0.0   0.0   0.0  0.000000  0.001773     0.0  \n",
              "3   0.0   0.0   0.0  0.000000  0.001773     0.0  \n",
              "4   0.0   0.0   0.0  0.000000  0.001773     0.0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ]
          },
          "execution_count": 441,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### 8. Describe the heart dataset after implementing the min max normalization\n",
        "#Normalize data (range 0 - 1)\n",
        "minx = np.min(x)\n",
        "maxx = np.max(x)\n",
        "x = (x - minx) / (maxx - minx)\n",
        "x.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 442,
      "metadata": {
        "id": "lvykedw82t3u"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(181, 21)\n",
            "(61, 21)\n",
            "(61, 21)\n"
          ]
        }
      ],
      "source": [
        "### 9. Modify the code to split the dataset into train and test (train 70%, val 20% and test 10%).\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "# re-create train and validation set\n",
        "x_train, x_val, y_train, y_val  = train_test_split(x_train, y_train, test_size=0.25, random_state=42)\n",
        "# train 70%, validation 20%, test 10%\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 443,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train = np.asarray(x_train).astype(np.float32)\n",
        "y_train = np.asarray(y_train).astype(np.float32)\n",
        "x_val = np.asarray(x_train).astype(np.float32)\n",
        "y_val = np.asarray(y_train).astype(np.float32)\n",
        "x_test = np.asarray(x_train).astype(np.float32)\n",
        "y_test = np.asarray(y_train).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 444,
      "metadata": {
        "id": "-Pwz5A_j2t30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_69 (Dense)            (None, 64)                1408      \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3521 (13.75 KB)\n",
            "Trainable params: 3521 (13.75 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "### 10. What is the purpose of each layer in the neural network created using the Sequential() function with 64, 32, and 1 neurons,\n",
        "### respectively, and softmax and sigmoid activation functions?\n",
        "\n",
        "model = Sequential() #Allow us to create model layer by layer\n",
        "model.add(Dense(64, input_dim=21, activation='softmax')) #Softmax turn number data into probabilities which sum to 1\n",
        "model.add(Dense(32, activation='softmax'))\n",
        "model.add(Dense(1, activation='sigmoid')) # produce probability value (number between 0 or 1)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 445,
      "metadata": {
        "id": "D0pM4z_OQfNi"
      },
      "outputs": [],
      "source": [
        "### 11. This code compiles a neural network model with a mean squared error loss function, the Adam optimizer with a learning rate of 0.01,\n",
        "### and accuracy as a performance metric. What does each of these components mean, and how do they affect the model training and performance?\n",
        "\n",
        "model.compile(loss='mse',\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.01, beta_1=0.9, beta_2=0.999,epsilon=1e-07, amsgrad=False,name='Adam'),\n",
        "              metrics=['acc'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 446,
      "metadata": {
        "id": "unxSIBnZ2t36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "12/12 [==============================] - 1s 13ms/step - loss: 0.2499 - acc: 0.4917 - val_loss: 0.2484 - val_acc: 0.5580\n",
            "Epoch 2/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.5580 - val_loss: 0.2469 - val_acc: 0.5580\n",
            "Epoch 3/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 4/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 5/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 6/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 7/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 8/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2473 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 9/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2470 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 10/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 11/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2470 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 12/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 13/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2469 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 14/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 15/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 16/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 17/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 18/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2470 - acc: 0.5580 - val_loss: 0.2468 - val_acc: 0.5580\n",
            "Epoch 19/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2472 - acc: 0.5580 - val_loss: 0.2468 - val_acc: 0.5580\n",
            "Epoch 20/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2469 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 21/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2474 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 22/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 23/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.5580 - val_loss: 0.2469 - val_acc: 0.5580\n",
            "Epoch 24/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2469 - acc: 0.5580 - val_loss: 0.2470 - val_acc: 0.5580\n",
            "Epoch 25/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 26/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2471 - acc: 0.5580 - val_loss: 0.2467 - val_acc: 0.5580\n",
            "Epoch 27/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 28/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 29/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 30/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2473 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 31/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2470 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 32/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 33/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2465 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 34/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2468 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 35/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2468 - val_acc: 0.5580\n",
            "Epoch 36/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2470 - acc: 0.5580 - val_loss: 0.2465 - val_acc: 0.5580\n",
            "Epoch 37/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2466 - val_acc: 0.5580\n",
            "Epoch 38/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2465 - acc: 0.5580 - val_loss: 0.2464 - val_acc: 0.5580\n",
            "Epoch 39/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2464 - acc: 0.5580 - val_loss: 0.2463 - val_acc: 0.5580\n",
            "Epoch 40/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2463 - acc: 0.5580 - val_loss: 0.2462 - val_acc: 0.5580\n",
            "Epoch 41/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2467 - acc: 0.5580 - val_loss: 0.2462 - val_acc: 0.5580\n",
            "Epoch 42/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.2463 - acc: 0.5580 - val_loss: 0.2462 - val_acc: 0.5580\n",
            "Epoch 43/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2464 - acc: 0.5580 - val_loss: 0.2462 - val_acc: 0.5580\n",
            "Epoch 44/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2466 - acc: 0.5580 - val_loss: 0.2460 - val_acc: 0.5580\n",
            "Epoch 45/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2461 - acc: 0.5580 - val_loss: 0.2460 - val_acc: 0.5580\n",
            "Epoch 46/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2461 - acc: 0.5580 - val_loss: 0.2458 - val_acc: 0.5580\n",
            "Epoch 47/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2460 - acc: 0.5580 - val_loss: 0.2459 - val_acc: 0.5580\n",
            "Epoch 48/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2464 - acc: 0.5580 - val_loss: 0.2454 - val_acc: 0.5580\n",
            "Epoch 49/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.2464 - acc: 0.5580 - val_loss: 0.2454 - val_acc: 0.5580\n",
            "Epoch 50/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2457 - acc: 0.5580 - val_loss: 0.2452 - val_acc: 0.5580\n",
            "Epoch 51/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2452 - acc: 0.5580 - val_loss: 0.2451 - val_acc: 0.5580\n",
            "Epoch 52/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2453 - acc: 0.5580 - val_loss: 0.2447 - val_acc: 0.5580\n",
            "Epoch 53/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2450 - acc: 0.5580 - val_loss: 0.2444 - val_acc: 0.5580\n",
            "Epoch 54/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2447 - acc: 0.5580 - val_loss: 0.2444 - val_acc: 0.5580\n",
            "Epoch 55/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2441 - acc: 0.5580 - val_loss: 0.2434 - val_acc: 0.5580\n",
            "Epoch 56/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.2433 - acc: 0.5580 - val_loss: 0.2428 - val_acc: 0.5580\n",
            "Epoch 57/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2431 - acc: 0.5580 - val_loss: 0.2421 - val_acc: 0.5580\n",
            "Epoch 58/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2415 - acc: 0.5580 - val_loss: 0.2416 - val_acc: 0.5580\n",
            "Epoch 59/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2415 - acc: 0.5580 - val_loss: 0.2411 - val_acc: 0.5580\n",
            "Epoch 60/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2416 - acc: 0.5580 - val_loss: 0.2394 - val_acc: 0.5580\n",
            "Epoch 61/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.2393 - acc: 0.5580 - val_loss: 0.2386 - val_acc: 0.5580\n",
            "Epoch 62/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2380 - acc: 0.5580 - val_loss: 0.2368 - val_acc: 0.5525\n",
            "Epoch 63/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2365 - acc: 0.5801 - val_loss: 0.2354 - val_acc: 0.6077\n",
            "Epoch 64/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2348 - acc: 0.5967 - val_loss: 0.2333 - val_acc: 0.6022\n",
            "Epoch 65/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2326 - acc: 0.6298 - val_loss: 0.2311 - val_acc: 0.6298\n",
            "Epoch 66/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2328 - acc: 0.5801 - val_loss: 0.2285 - val_acc: 0.6685\n",
            "Epoch 67/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2284 - acc: 0.6740 - val_loss: 0.2261 - val_acc: 0.6961\n",
            "Epoch 68/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2252 - acc: 0.6851 - val_loss: 0.2231 - val_acc: 0.6685\n",
            "Epoch 69/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2228 - acc: 0.6630 - val_loss: 0.2204 - val_acc: 0.7127\n",
            "Epoch 70/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2204 - acc: 0.7127 - val_loss: 0.2166 - val_acc: 0.6851\n",
            "Epoch 71/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2191 - acc: 0.6740 - val_loss: 0.2140 - val_acc: 0.6851\n",
            "Epoch 72/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2136 - acc: 0.6961 - val_loss: 0.2111 - val_acc: 0.7072\n",
            "Epoch 73/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2106 - acc: 0.6961 - val_loss: 0.2073 - val_acc: 0.7072\n",
            "Epoch 74/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2067 - acc: 0.7017 - val_loss: 0.2043 - val_acc: 0.6906\n",
            "Epoch 75/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2035 - acc: 0.7072 - val_loss: 0.2018 - val_acc: 0.7127\n",
            "Epoch 76/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2012 - acc: 0.7182 - val_loss: 0.1993 - val_acc: 0.7127\n",
            "Epoch 77/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2001 - acc: 0.6851 - val_loss: 0.1976 - val_acc: 0.7127\n",
            "Epoch 78/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2031 - acc: 0.7072 - val_loss: 0.1957 - val_acc: 0.6906\n",
            "Epoch 79/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1994 - acc: 0.6906 - val_loss: 0.1938 - val_acc: 0.7072\n",
            "Epoch 80/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1945 - acc: 0.7072 - val_loss: 0.1925 - val_acc: 0.7072\n",
            "Epoch 81/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1926 - acc: 0.7017 - val_loss: 0.1911 - val_acc: 0.7127\n",
            "Epoch 82/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1918 - acc: 0.7072 - val_loss: 0.1899 - val_acc: 0.7072\n",
            "Epoch 83/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1911 - acc: 0.6906 - val_loss: 0.1885 - val_acc: 0.7127\n",
            "Epoch 84/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1904 - acc: 0.6961 - val_loss: 0.1878 - val_acc: 0.7127\n",
            "Epoch 85/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1882 - acc: 0.7182 - val_loss: 0.1871 - val_acc: 0.7072\n",
            "Epoch 86/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1881 - acc: 0.7182 - val_loss: 0.1860 - val_acc: 0.7182\n",
            "Epoch 87/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1939 - acc: 0.7017 - val_loss: 0.1857 - val_acc: 0.7072\n",
            "Epoch 88/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1951 - acc: 0.6851 - val_loss: 0.1856 - val_acc: 0.6906\n",
            "Epoch 89/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1885 - acc: 0.6961 - val_loss: 0.1861 - val_acc: 0.6961\n",
            "Epoch 90/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1888 - acc: 0.7127 - val_loss: 0.1838 - val_acc: 0.7127\n",
            "Epoch 91/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1880 - acc: 0.6906 - val_loss: 0.1831 - val_acc: 0.7127\n",
            "Epoch 92/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1847 - acc: 0.7182 - val_loss: 0.1830 - val_acc: 0.7127\n",
            "Epoch 93/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1830 - acc: 0.7072 - val_loss: 0.1822 - val_acc: 0.7238\n",
            "Epoch 94/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1838 - acc: 0.7182 - val_loss: 0.1817 - val_acc: 0.7238\n",
            "Epoch 95/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1822 - acc: 0.7127 - val_loss: 0.1813 - val_acc: 0.7127\n",
            "Epoch 96/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1844 - acc: 0.7017 - val_loss: 0.1804 - val_acc: 0.7127\n",
            "Epoch 97/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1834 - acc: 0.7072 - val_loss: 0.1800 - val_acc: 0.7182\n",
            "Epoch 98/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1829 - acc: 0.7072 - val_loss: 0.1803 - val_acc: 0.7127\n",
            "Epoch 99/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1861 - acc: 0.6961 - val_loss: 0.1792 - val_acc: 0.7127\n",
            "Epoch 100/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1830 - acc: 0.7072 - val_loss: 0.1796 - val_acc: 0.7072\n",
            "Epoch 101/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1803 - acc: 0.7293 - val_loss: 0.1797 - val_acc: 0.7017\n",
            "Epoch 102/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1779 - acc: 0.7182 - val_loss: 0.1790 - val_acc: 0.7127\n",
            "Epoch 103/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1804 - acc: 0.6961 - val_loss: 0.1777 - val_acc: 0.7182\n",
            "Epoch 104/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1803 - acc: 0.7127 - val_loss: 0.1777 - val_acc: 0.7072\n",
            "Epoch 105/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1853 - acc: 0.7017 - val_loss: 0.1783 - val_acc: 0.7127\n",
            "Epoch 106/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1749 - acc: 0.7348 - val_loss: 0.1817 - val_acc: 0.7127\n",
            "Epoch 107/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1785 - acc: 0.7072 - val_loss: 0.1771 - val_acc: 0.7127\n",
            "Epoch 108/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1771 - acc: 0.7127 - val_loss: 0.1760 - val_acc: 0.7238\n",
            "Epoch 109/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1766 - acc: 0.7182 - val_loss: 0.1758 - val_acc: 0.7127\n",
            "Epoch 110/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1764 - acc: 0.7127 - val_loss: 0.1767 - val_acc: 0.7072\n",
            "Epoch 111/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1779 - acc: 0.7127 - val_loss: 0.1753 - val_acc: 0.7127\n",
            "Epoch 112/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1781 - acc: 0.7182 - val_loss: 0.1748 - val_acc: 0.7182\n",
            "Epoch 113/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1785 - acc: 0.7017 - val_loss: 0.1762 - val_acc: 0.7017\n",
            "Epoch 114/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1740 - acc: 0.6961 - val_loss: 0.1765 - val_acc: 0.7182\n",
            "Epoch 115/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1756 - acc: 0.7127 - val_loss: 0.1739 - val_acc: 0.7182\n",
            "Epoch 116/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1757 - acc: 0.7182 - val_loss: 0.1737 - val_acc: 0.7127\n",
            "Epoch 117/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1748 - acc: 0.7072 - val_loss: 0.1735 - val_acc: 0.7182\n",
            "Epoch 118/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1754 - acc: 0.7127 - val_loss: 0.1732 - val_acc: 0.7238\n",
            "Epoch 119/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1740 - acc: 0.7127 - val_loss: 0.1728 - val_acc: 0.7072\n",
            "Epoch 120/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1746 - acc: 0.7072 - val_loss: 0.1723 - val_acc: 0.7127\n",
            "Epoch 121/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1732 - acc: 0.7127 - val_loss: 0.1721 - val_acc: 0.7238\n",
            "Epoch 122/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1770 - acc: 0.7072 - val_loss: 0.1716 - val_acc: 0.7182\n",
            "Epoch 123/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1716 - acc: 0.7348 - val_loss: 0.1742 - val_acc: 0.7293\n",
            "Epoch 124/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1784 - acc: 0.7238 - val_loss: 0.1727 - val_acc: 0.7348\n",
            "Epoch 125/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1723 - acc: 0.7293 - val_loss: 0.1738 - val_acc: 0.7293\n",
            "Epoch 126/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1732 - acc: 0.7072 - val_loss: 0.1706 - val_acc: 0.7072\n",
            "Epoch 127/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1718 - acc: 0.7182 - val_loss: 0.1702 - val_acc: 0.7238\n",
            "Epoch 128/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1715 - acc: 0.7127 - val_loss: 0.1701 - val_acc: 0.7127\n",
            "Epoch 129/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1710 - acc: 0.7072 - val_loss: 0.1695 - val_acc: 0.7182\n",
            "Epoch 130/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1710 - acc: 0.7182 - val_loss: 0.1693 - val_acc: 0.7238\n",
            "Epoch 131/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1694 - acc: 0.7182 - val_loss: 0.1701 - val_acc: 0.7127\n",
            "Epoch 132/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1709 - acc: 0.7238 - val_loss: 0.1687 - val_acc: 0.7072\n",
            "Epoch 133/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1694 - acc: 0.7293 - val_loss: 0.1683 - val_acc: 0.7182\n",
            "Epoch 134/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1697 - acc: 0.7017 - val_loss: 0.1681 - val_acc: 0.7238\n",
            "Epoch 135/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1688 - acc: 0.7182 - val_loss: 0.1678 - val_acc: 0.7238\n",
            "Epoch 136/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1731 - acc: 0.7127 - val_loss: 0.1699 - val_acc: 0.7403\n",
            "Epoch 137/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1782 - acc: 0.7238 - val_loss: 0.1702 - val_acc: 0.7403\n",
            "Epoch 138/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1707 - acc: 0.7238 - val_loss: 0.1688 - val_acc: 0.7293\n",
            "Epoch 139/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1678 - acc: 0.7127 - val_loss: 0.1668 - val_acc: 0.7348\n",
            "Epoch 140/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1707 - acc: 0.7459 - val_loss: 0.1674 - val_acc: 0.7459\n",
            "Epoch 141/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1689 - acc: 0.7293 - val_loss: 0.1671 - val_acc: 0.7182\n",
            "Epoch 142/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1677 - acc: 0.7403 - val_loss: 0.1683 - val_acc: 0.7403\n",
            "Epoch 143/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1682 - acc: 0.7403 - val_loss: 0.1657 - val_acc: 0.7403\n",
            "Epoch 144/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1685 - acc: 0.7348 - val_loss: 0.1675 - val_acc: 0.7459\n",
            "Epoch 145/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1664 - acc: 0.7238 - val_loss: 0.1659 - val_acc: 0.7459\n",
            "Epoch 146/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1673 - acc: 0.7348 - val_loss: 0.1649 - val_acc: 0.7403\n",
            "Epoch 147/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1722 - acc: 0.7293 - val_loss: 0.1666 - val_acc: 0.7514\n",
            "Epoch 148/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1696 - acc: 0.7238 - val_loss: 0.1670 - val_acc: 0.7403\n",
            "Epoch 149/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1666 - acc: 0.7293 - val_loss: 0.1649 - val_acc: 0.7459\n",
            "Epoch 150/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1677 - acc: 0.7293 - val_loss: 0.1641 - val_acc: 0.7293\n",
            "Epoch 151/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1638 - acc: 0.7459 - val_loss: 0.1658 - val_acc: 0.7514\n",
            "Epoch 152/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1649 - acc: 0.7459 - val_loss: 0.1637 - val_acc: 0.7293\n",
            "Epoch 153/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1647 - acc: 0.7348 - val_loss: 0.1634 - val_acc: 0.7459\n",
            "Epoch 154/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1634 - acc: 0.7293 - val_loss: 0.1631 - val_acc: 0.7348\n",
            "Epoch 155/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1639 - acc: 0.7293 - val_loss: 0.1626 - val_acc: 0.7348\n",
            "Epoch 156/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1686 - acc: 0.7514 - val_loss: 0.1630 - val_acc: 0.7514\n",
            "Epoch 157/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1630 - acc: 0.7514 - val_loss: 0.1623 - val_acc: 0.7403\n",
            "Epoch 158/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1659 - acc: 0.7238 - val_loss: 0.1623 - val_acc: 0.7459\n",
            "Epoch 159/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1647 - acc: 0.7238 - val_loss: 0.1624 - val_acc: 0.7403\n",
            "Epoch 160/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1612 - acc: 0.7403 - val_loss: 0.1618 - val_acc: 0.7514\n",
            "Epoch 161/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1642 - acc: 0.7514 - val_loss: 0.1620 - val_acc: 0.7514\n",
            "Epoch 162/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1614 - acc: 0.7514 - val_loss: 0.1611 - val_acc: 0.7403\n",
            "Epoch 163/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1639 - acc: 0.7403 - val_loss: 0.1608 - val_acc: 0.7459\n",
            "Epoch 164/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1638 - acc: 0.7514 - val_loss: 0.1608 - val_acc: 0.7514\n",
            "Epoch 165/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1604 - acc: 0.7514 - val_loss: 0.1602 - val_acc: 0.7403\n",
            "Epoch 166/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1686 - acc: 0.7293 - val_loss: 0.1611 - val_acc: 0.7514\n",
            "Epoch 167/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1629 - acc: 0.7514 - val_loss: 0.1619 - val_acc: 0.7569\n",
            "Epoch 168/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1624 - acc: 0.7293 - val_loss: 0.1594 - val_acc: 0.7403\n",
            "Epoch 169/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1631 - acc: 0.7459 - val_loss: 0.1596 - val_acc: 0.7514\n",
            "Epoch 170/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1601 - acc: 0.7514 - val_loss: 0.1590 - val_acc: 0.7403\n",
            "Epoch 171/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1598 - acc: 0.7514 - val_loss: 0.1595 - val_acc: 0.7514\n",
            "Epoch 172/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1610 - acc: 0.7403 - val_loss: 0.1584 - val_acc: 0.7403\n",
            "Epoch 173/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1613 - acc: 0.7514 - val_loss: 0.1581 - val_acc: 0.7459\n",
            "Epoch 174/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1598 - acc: 0.7459 - val_loss: 0.1580 - val_acc: 0.7459\n",
            "Epoch 175/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1595 - acc: 0.7514 - val_loss: 0.1584 - val_acc: 0.7514\n",
            "Epoch 176/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1590 - acc: 0.7514 - val_loss: 0.1574 - val_acc: 0.7403\n",
            "Epoch 177/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1589 - acc: 0.7459 - val_loss: 0.1571 - val_acc: 0.7403\n",
            "Epoch 178/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1640 - acc: 0.7459 - val_loss: 0.1579 - val_acc: 0.7514\n",
            "Epoch 179/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1673 - acc: 0.7293 - val_loss: 0.1601 - val_acc: 0.7514\n",
            "Epoch 180/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1647 - acc: 0.7403 - val_loss: 0.1663 - val_acc: 0.7514\n",
            "Epoch 181/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1644 - acc: 0.7459 - val_loss: 0.1577 - val_acc: 0.7680\n",
            "Epoch 182/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1579 - acc: 0.7514 - val_loss: 0.1561 - val_acc: 0.7403\n",
            "Epoch 183/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1574 - acc: 0.7514 - val_loss: 0.1560 - val_acc: 0.7459\n",
            "Epoch 184/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1574 - acc: 0.7514 - val_loss: 0.1556 - val_acc: 0.7514\n",
            "Epoch 185/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1565 - acc: 0.7403 - val_loss: 0.1563 - val_acc: 0.7624\n",
            "Epoch 186/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1567 - acc: 0.7569 - val_loss: 0.1552 - val_acc: 0.7459\n",
            "Epoch 187/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1565 - acc: 0.7514 - val_loss: 0.1549 - val_acc: 0.7459\n",
            "Epoch 188/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1548 - acc: 0.7403 - val_loss: 0.1555 - val_acc: 0.7569\n",
            "Epoch 189/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1564 - acc: 0.7624 - val_loss: 0.1544 - val_acc: 0.7459\n",
            "Epoch 190/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1555 - acc: 0.7459 - val_loss: 0.1543 - val_acc: 0.7459\n",
            "Epoch 191/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1573 - acc: 0.7569 - val_loss: 0.1539 - val_acc: 0.7514\n",
            "Epoch 192/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1570 - acc: 0.7680 - val_loss: 0.1552 - val_acc: 0.7569\n",
            "Epoch 193/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1554 - acc: 0.7680 - val_loss: 0.1541 - val_acc: 0.7569\n",
            "Epoch 194/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1546 - acc: 0.7459 - val_loss: 0.1532 - val_acc: 0.7459\n",
            "Epoch 195/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1537 - acc: 0.7459 - val_loss: 0.1529 - val_acc: 0.7514\n",
            "Epoch 196/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1559 - acc: 0.7569 - val_loss: 0.1528 - val_acc: 0.7514\n",
            "Epoch 197/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1568 - acc: 0.7735 - val_loss: 0.1564 - val_acc: 0.7790\n",
            "Epoch 198/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1624 - acc: 0.7569 - val_loss: 0.1535 - val_acc: 0.7735\n",
            "Epoch 199/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1533 - acc: 0.7680 - val_loss: 0.1539 - val_acc: 0.7680\n",
            "Epoch 200/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1529 - acc: 0.7624 - val_loss: 0.1523 - val_acc: 0.7569\n",
            "Epoch 201/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1553 - acc: 0.7680 - val_loss: 0.1516 - val_acc: 0.7459\n",
            "Epoch 202/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1520 - acc: 0.7459 - val_loss: 0.1515 - val_acc: 0.7459\n",
            "Epoch 203/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1536 - acc: 0.7569 - val_loss: 0.1513 - val_acc: 0.7569\n",
            "Epoch 204/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1529 - acc: 0.7680 - val_loss: 0.1522 - val_acc: 0.7624\n",
            "Epoch 205/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1522 - acc: 0.7680 - val_loss: 0.1507 - val_acc: 0.7569\n",
            "Epoch 206/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1543 - acc: 0.7514 - val_loss: 0.1503 - val_acc: 0.7514\n",
            "Epoch 207/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1524 - acc: 0.7459 - val_loss: 0.1502 - val_acc: 0.7514\n",
            "Epoch 208/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1508 - acc: 0.7514 - val_loss: 0.1499 - val_acc: 0.7459\n",
            "Epoch 209/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1508 - acc: 0.7514 - val_loss: 0.1496 - val_acc: 0.7459\n",
            "Epoch 210/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1495 - acc: 0.7624 - val_loss: 0.1501 - val_acc: 0.7680\n",
            "Epoch 211/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1512 - acc: 0.7790 - val_loss: 0.1493 - val_acc: 0.7569\n",
            "Epoch 212/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1500 - acc: 0.7569 - val_loss: 0.1489 - val_acc: 0.7569\n",
            "Epoch 213/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1529 - acc: 0.7624 - val_loss: 0.1485 - val_acc: 0.7514\n",
            "Epoch 214/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1499 - acc: 0.7735 - val_loss: 0.1482 - val_acc: 0.7569\n",
            "Epoch 215/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1476 - acc: 0.7569 - val_loss: 0.1499 - val_acc: 0.7790\n",
            "Epoch 216/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1497 - acc: 0.7624 - val_loss: 0.1477 - val_acc: 0.7569\n",
            "Epoch 217/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1511 - acc: 0.7569 - val_loss: 0.1475 - val_acc: 0.7569\n",
            "Epoch 218/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1485 - acc: 0.7624 - val_loss: 0.1474 - val_acc: 0.7624\n",
            "Epoch 219/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1482 - acc: 0.7569 - val_loss: 0.1470 - val_acc: 0.7569\n",
            "Epoch 220/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1505 - acc: 0.7680 - val_loss: 0.1466 - val_acc: 0.7569\n",
            "Epoch 221/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1482 - acc: 0.7790 - val_loss: 0.1476 - val_acc: 0.7735\n",
            "Epoch 222/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1462 - acc: 0.7569 - val_loss: 0.1474 - val_acc: 0.7735\n",
            "Epoch 223/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1484 - acc: 0.7735 - val_loss: 0.1460 - val_acc: 0.7624\n",
            "Epoch 224/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1486 - acc: 0.7790 - val_loss: 0.1482 - val_acc: 0.7901\n",
            "Epoch 225/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1473 - acc: 0.7624 - val_loss: 0.1462 - val_acc: 0.7790\n",
            "Epoch 226/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1464 - acc: 0.7735 - val_loss: 0.1456 - val_acc: 0.7735\n",
            "Epoch 227/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1471 - acc: 0.7735 - val_loss: 0.1454 - val_acc: 0.7735\n",
            "Epoch 228/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1503 - acc: 0.7624 - val_loss: 0.1448 - val_acc: 0.7735\n",
            "Epoch 229/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1460 - acc: 0.7680 - val_loss: 0.1455 - val_acc: 0.7790\n",
            "Epoch 230/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1456 - acc: 0.7624 - val_loss: 0.1442 - val_acc: 0.7624\n",
            "Epoch 231/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1468 - acc: 0.7735 - val_loss: 0.1439 - val_acc: 0.7624\n",
            "Epoch 232/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1449 - acc: 0.7680 - val_loss: 0.1436 - val_acc: 0.7680\n",
            "Epoch 233/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1437 - acc: 0.7624 - val_loss: 0.1433 - val_acc: 0.7680\n",
            "Epoch 234/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1453 - acc: 0.7845 - val_loss: 0.1433 - val_acc: 0.7735\n",
            "Epoch 235/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1452 - acc: 0.7735 - val_loss: 0.1429 - val_acc: 0.7680\n",
            "Epoch 236/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1441 - acc: 0.7735 - val_loss: 0.1425 - val_acc: 0.7680\n",
            "Epoch 237/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1428 - acc: 0.7680 - val_loss: 0.1422 - val_acc: 0.7680\n",
            "Epoch 238/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1434 - acc: 0.7735 - val_loss: 0.1419 - val_acc: 0.7680\n",
            "Epoch 239/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1419 - acc: 0.7680 - val_loss: 0.1418 - val_acc: 0.7845\n",
            "Epoch 240/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1455 - acc: 0.7901 - val_loss: 0.1413 - val_acc: 0.7624\n",
            "Epoch 241/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1484 - acc: 0.7790 - val_loss: 0.1413 - val_acc: 0.7735\n",
            "Epoch 242/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1426 - acc: 0.7790 - val_loss: 0.1416 - val_acc: 0.7901\n",
            "Epoch 243/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1419 - acc: 0.7901 - val_loss: 0.1409 - val_acc: 0.7790\n",
            "Epoch 244/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1529 - acc: 0.7624 - val_loss: 0.1403 - val_acc: 0.7680\n",
            "Epoch 245/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1481 - acc: 0.7735 - val_loss: 0.1429 - val_acc: 0.7901\n",
            "Epoch 246/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1503 - acc: 0.7735 - val_loss: 0.1408 - val_acc: 0.7956\n",
            "Epoch 247/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1462 - acc: 0.7901 - val_loss: 0.1406 - val_acc: 0.7901\n",
            "Epoch 248/1000\n",
            "12/12 [==============================] - 0s 13ms/step - loss: 0.1433 - acc: 0.7680 - val_loss: 0.1422 - val_acc: 0.7956\n",
            "Epoch 249/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1386 - acc: 0.7901 - val_loss: 0.1399 - val_acc: 0.7956\n",
            "Epoch 250/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1414 - acc: 0.7680 - val_loss: 0.1388 - val_acc: 0.7735\n",
            "Epoch 251/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1386 - acc: 0.7901 - val_loss: 0.1408 - val_acc: 0.7956\n",
            "Epoch 252/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1400 - acc: 0.7845 - val_loss: 0.1381 - val_acc: 0.7790\n",
            "Epoch 253/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1387 - acc: 0.7845 - val_loss: 0.1381 - val_acc: 0.7845\n",
            "Epoch 254/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1401 - acc: 0.7901 - val_loss: 0.1381 - val_acc: 0.7956\n",
            "Epoch 255/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1387 - acc: 0.7735 - val_loss: 0.1372 - val_acc: 0.7845\n",
            "Epoch 256/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1420 - acc: 0.7901 - val_loss: 0.1371 - val_acc: 0.7956\n",
            "Epoch 257/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1394 - acc: 0.8177 - val_loss: 0.1370 - val_acc: 0.8011\n",
            "Epoch 258/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1392 - acc: 0.8122 - val_loss: 0.1384 - val_acc: 0.7956\n",
            "Epoch 259/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1369 - acc: 0.7901 - val_loss: 0.1376 - val_acc: 0.8066\n",
            "Epoch 260/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1379 - acc: 0.7956 - val_loss: 0.1359 - val_acc: 0.7901\n",
            "Epoch 261/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1375 - acc: 0.7901 - val_loss: 0.1356 - val_acc: 0.7901\n",
            "Epoch 262/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1361 - acc: 0.8011 - val_loss: 0.1354 - val_acc: 0.7956\n",
            "Epoch 263/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1372 - acc: 0.7956 - val_loss: 0.1353 - val_acc: 0.8011\n",
            "Epoch 264/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1363 - acc: 0.7956 - val_loss: 0.1352 - val_acc: 0.7956\n",
            "Epoch 265/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1356 - acc: 0.7956 - val_loss: 0.1346 - val_acc: 0.8011\n",
            "Epoch 266/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1370 - acc: 0.8011 - val_loss: 0.1342 - val_acc: 0.8011\n",
            "Epoch 267/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1347 - acc: 0.8011 - val_loss: 0.1342 - val_acc: 0.8011\n",
            "Epoch 268/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1410 - acc: 0.7956 - val_loss: 0.1343 - val_acc: 0.8122\n",
            "Epoch 269/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1374 - acc: 0.8066 - val_loss: 0.1339 - val_acc: 0.8011\n",
            "Epoch 270/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1369 - acc: 0.8066 - val_loss: 0.1334 - val_acc: 0.8011\n",
            "Epoch 271/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1341 - acc: 0.8011 - val_loss: 0.1329 - val_acc: 0.8066\n",
            "Epoch 272/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.1350 - acc: 0.7956 - val_loss: 0.1326 - val_acc: 0.8122\n",
            "Epoch 273/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1349 - acc: 0.8011 - val_loss: 0.1323 - val_acc: 0.8011\n",
            "Epoch 274/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1357 - acc: 0.8122 - val_loss: 0.1324 - val_acc: 0.8066\n",
            "Epoch 275/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1327 - acc: 0.7956 - val_loss: 0.1318 - val_acc: 0.8066\n",
            "Epoch 276/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1324 - acc: 0.7901 - val_loss: 0.1317 - val_acc: 0.8066\n",
            "Epoch 277/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1336 - acc: 0.8011 - val_loss: 0.1313 - val_acc: 0.8177\n",
            "Epoch 278/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1424 - acc: 0.7845 - val_loss: 0.1318 - val_acc: 0.8066\n",
            "Epoch 279/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1442 - acc: 0.7901 - val_loss: 0.1324 - val_acc: 0.8066\n",
            "Epoch 280/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - acc: 0.8177 - val_loss: 0.1322 - val_acc: 0.8232\n",
            "Epoch 281/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1332 - acc: 0.7956 - val_loss: 0.1303 - val_acc: 0.8122\n",
            "Epoch 282/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1316 - acc: 0.8122 - val_loss: 0.1300 - val_acc: 0.8122\n",
            "Epoch 283/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1306 - acc: 0.8232 - val_loss: 0.1297 - val_acc: 0.8122\n",
            "Epoch 284/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1302 - acc: 0.8232 - val_loss: 0.1296 - val_acc: 0.8232\n",
            "Epoch 285/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1313 - acc: 0.8177 - val_loss: 0.1292 - val_acc: 0.8177\n",
            "Epoch 286/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1306 - acc: 0.8177 - val_loss: 0.1290 - val_acc: 0.8232\n",
            "Epoch 287/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - acc: 0.8343 - val_loss: 0.1287 - val_acc: 0.8287\n",
            "Epoch 288/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1315 - acc: 0.8122 - val_loss: 0.1284 - val_acc: 0.8232\n",
            "Epoch 289/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - acc: 0.8122 - val_loss: 0.1282 - val_acc: 0.8343\n",
            "Epoch 290/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1309 - acc: 0.7956 - val_loss: 0.1291 - val_acc: 0.8232\n",
            "Epoch 291/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1316 - acc: 0.8122 - val_loss: 0.1276 - val_acc: 0.8177\n",
            "Epoch 292/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1292 - acc: 0.8122 - val_loss: 0.1276 - val_acc: 0.8232\n",
            "Epoch 293/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - acc: 0.8122 - val_loss: 0.1272 - val_acc: 0.8343\n",
            "Epoch 294/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1307 - acc: 0.8177 - val_loss: 0.1269 - val_acc: 0.8232\n",
            "Epoch 295/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1291 - acc: 0.8398 - val_loss: 0.1268 - val_acc: 0.8343\n",
            "Epoch 296/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1275 - acc: 0.8343 - val_loss: 0.1263 - val_acc: 0.8232\n",
            "Epoch 297/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1281 - acc: 0.8232 - val_loss: 0.1273 - val_acc: 0.8232\n",
            "Epoch 298/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1319 - acc: 0.8287 - val_loss: 0.1258 - val_acc: 0.8232\n",
            "Epoch 299/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1270 - acc: 0.8232 - val_loss: 0.1255 - val_acc: 0.8232\n",
            "Epoch 300/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1279 - acc: 0.8232 - val_loss: 0.1255 - val_acc: 0.8287\n",
            "Epoch 301/1000\n",
            "12/12 [==============================] - 0s 10ms/step - loss: 0.1342 - acc: 0.8011 - val_loss: 0.1255 - val_acc: 0.8232\n",
            "Epoch 302/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1273 - acc: 0.8287 - val_loss: 0.1254 - val_acc: 0.8508\n",
            "Epoch 303/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1244 - acc: 0.8343 - val_loss: 0.1267 - val_acc: 0.8232\n",
            "Epoch 304/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1319 - acc: 0.8011 - val_loss: 0.1244 - val_acc: 0.8343\n",
            "Epoch 305/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1314 - acc: 0.8177 - val_loss: 0.1242 - val_acc: 0.8343\n",
            "Epoch 306/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1299 - acc: 0.8177 - val_loss: 0.1241 - val_acc: 0.8287\n",
            "Epoch 307/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1270 - acc: 0.8232 - val_loss: 0.1238 - val_acc: 0.8232\n",
            "Epoch 308/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1252 - acc: 0.8232 - val_loss: 0.1240 - val_acc: 0.8343\n",
            "Epoch 309/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1240 - acc: 0.8398 - val_loss: 0.1234 - val_acc: 0.8343\n",
            "Epoch 310/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1238 - acc: 0.8343 - val_loss: 0.1231 - val_acc: 0.8232\n",
            "Epoch 311/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1244 - acc: 0.8232 - val_loss: 0.1234 - val_acc: 0.8343\n",
            "Epoch 312/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1268 - acc: 0.8232 - val_loss: 0.1225 - val_acc: 0.8343\n",
            "Epoch 313/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1233 - acc: 0.8177 - val_loss: 0.1223 - val_acc: 0.8232\n",
            "Epoch 314/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1234 - acc: 0.8343 - val_loss: 0.1229 - val_acc: 0.8343\n",
            "Epoch 315/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1238 - acc: 0.8343 - val_loss: 0.1221 - val_acc: 0.8453\n",
            "Epoch 316/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1272 - acc: 0.8398 - val_loss: 0.1220 - val_acc: 0.8343\n",
            "Epoch 317/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1324 - acc: 0.8011 - val_loss: 0.1220 - val_acc: 0.8398\n",
            "Epoch 318/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1254 - acc: 0.8232 - val_loss: 0.1217 - val_acc: 0.8343\n",
            "Epoch 319/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1234 - acc: 0.8287 - val_loss: 0.1210 - val_acc: 0.8232\n",
            "Epoch 320/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1241 - acc: 0.8177 - val_loss: 0.1210 - val_acc: 0.8398\n",
            "Epoch 321/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1219 - acc: 0.8287 - val_loss: 0.1212 - val_acc: 0.8343\n",
            "Epoch 322/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1221 - acc: 0.8287 - val_loss: 0.1206 - val_acc: 0.8398\n",
            "Epoch 323/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1225 - acc: 0.8398 - val_loss: 0.1203 - val_acc: 0.8343\n",
            "Epoch 324/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1285 - acc: 0.8232 - val_loss: 0.1200 - val_acc: 0.8508\n",
            "Epoch 325/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1250 - acc: 0.8287 - val_loss: 0.1198 - val_acc: 0.8287\n",
            "Epoch 326/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1215 - acc: 0.8453 - val_loss: 0.1199 - val_acc: 0.8453\n",
            "Epoch 327/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1227 - acc: 0.8343 - val_loss: 0.1200 - val_acc: 0.8343\n",
            "Epoch 328/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1209 - acc: 0.8343 - val_loss: 0.1196 - val_acc: 0.8453\n",
            "Epoch 329/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1213 - acc: 0.8453 - val_loss: 0.1190 - val_acc: 0.8343\n",
            "Epoch 330/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1209 - acc: 0.8287 - val_loss: 0.1237 - val_acc: 0.8287\n",
            "Epoch 331/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1252 - acc: 0.8122 - val_loss: 0.1192 - val_acc: 0.8453\n",
            "Epoch 332/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1208 - acc: 0.8564 - val_loss: 0.1195 - val_acc: 0.8343\n",
            "Epoch 333/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1223 - acc: 0.8287 - val_loss: 0.1186 - val_acc: 0.8508\n",
            "Epoch 334/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1201 - acc: 0.8287 - val_loss: 0.1181 - val_acc: 0.8508\n",
            "Epoch 335/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.8398 - val_loss: 0.1179 - val_acc: 0.8343\n",
            "Epoch 336/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1213 - acc: 0.8343 - val_loss: 0.1185 - val_acc: 0.8343\n",
            "Epoch 337/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1222 - acc: 0.8287 - val_loss: 0.1175 - val_acc: 0.8398\n",
            "Epoch 338/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1194 - acc: 0.8564 - val_loss: 0.1174 - val_acc: 0.8453\n",
            "Epoch 339/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1209 - acc: 0.8398 - val_loss: 0.1173 - val_acc: 0.8508\n",
            "Epoch 340/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1198 - acc: 0.8398 - val_loss: 0.1179 - val_acc: 0.8343\n",
            "Epoch 341/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1271 - acc: 0.8122 - val_loss: 0.1170 - val_acc: 0.8287\n",
            "Epoch 342/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1293 - acc: 0.8066 - val_loss: 0.1167 - val_acc: 0.8398\n",
            "Epoch 343/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.8453 - val_loss: 0.1166 - val_acc: 0.8398\n",
            "Epoch 344/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1171 - acc: 0.8343 - val_loss: 0.1165 - val_acc: 0.8398\n",
            "Epoch 345/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1180 - acc: 0.8287 - val_loss: 0.1163 - val_acc: 0.8508\n",
            "Epoch 346/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1189 - acc: 0.8398 - val_loss: 0.1161 - val_acc: 0.8398\n",
            "Epoch 347/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1187 - acc: 0.8453 - val_loss: 0.1173 - val_acc: 0.8508\n",
            "Epoch 348/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1246 - acc: 0.8287 - val_loss: 0.1161 - val_acc: 0.8343\n",
            "Epoch 349/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1219 - acc: 0.8232 - val_loss: 0.1158 - val_acc: 0.8453\n",
            "Epoch 350/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1199 - acc: 0.8398 - val_loss: 0.1156 - val_acc: 0.8564\n",
            "Epoch 351/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1209 - acc: 0.8398 - val_loss: 0.1154 - val_acc: 0.8564\n",
            "Epoch 352/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1177 - acc: 0.8398 - val_loss: 0.1156 - val_acc: 0.8508\n",
            "Epoch 353/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.8453 - val_loss: 0.1165 - val_acc: 0.8398\n",
            "Epoch 354/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1219 - acc: 0.8287 - val_loss: 0.1153 - val_acc: 0.8508\n",
            "Epoch 355/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1195 - acc: 0.8453 - val_loss: 0.1149 - val_acc: 0.8564\n",
            "Epoch 356/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1159 - acc: 0.8453 - val_loss: 0.1157 - val_acc: 0.8343\n",
            "Epoch 357/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1170 - acc: 0.8343 - val_loss: 0.1145 - val_acc: 0.8619\n",
            "Epoch 358/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1185 - acc: 0.8453 - val_loss: 0.1152 - val_acc: 0.8343\n",
            "Epoch 359/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1156 - acc: 0.8398 - val_loss: 0.1148 - val_acc: 0.8343\n",
            "Epoch 360/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1165 - acc: 0.8398 - val_loss: 0.1143 - val_acc: 0.8398\n",
            "Epoch 361/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1210 - acc: 0.8398 - val_loss: 0.1138 - val_acc: 0.8508\n",
            "Epoch 362/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1187 - acc: 0.8508 - val_loss: 0.1142 - val_acc: 0.8343\n",
            "Epoch 363/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.8453 - val_loss: 0.1141 - val_acc: 0.8564\n",
            "Epoch 364/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1146 - acc: 0.8564 - val_loss: 0.1139 - val_acc: 0.8343\n",
            "Epoch 365/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1157 - acc: 0.8287 - val_loss: 0.1133 - val_acc: 0.8508\n",
            "Epoch 366/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.8453 - val_loss: 0.1136 - val_acc: 0.8343\n",
            "Epoch 367/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1176 - acc: 0.8232 - val_loss: 0.1139 - val_acc: 0.8453\n",
            "Epoch 368/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1151 - acc: 0.8398 - val_loss: 0.1129 - val_acc: 0.8508\n",
            "Epoch 369/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1155 - acc: 0.8343 - val_loss: 0.1132 - val_acc: 0.8564\n",
            "Epoch 370/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1158 - acc: 0.8508 - val_loss: 0.1127 - val_acc: 0.8508\n",
            "Epoch 371/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1152 - acc: 0.8398 - val_loss: 0.1131 - val_acc: 0.8619\n",
            "Epoch 372/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1159 - acc: 0.8343 - val_loss: 0.1130 - val_acc: 0.8453\n",
            "Epoch 373/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1172 - acc: 0.8398 - val_loss: 0.1126 - val_acc: 0.8564\n",
            "Epoch 374/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1150 - acc: 0.8453 - val_loss: 0.1123 - val_acc: 0.8564\n",
            "Epoch 375/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1144 - acc: 0.8343 - val_loss: 0.1120 - val_acc: 0.8564\n",
            "Epoch 376/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1124 - acc: 0.8508 - val_loss: 0.1120 - val_acc: 0.8564\n",
            "Epoch 377/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1132 - acc: 0.8508 - val_loss: 0.1116 - val_acc: 0.8508\n",
            "Epoch 378/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1139 - acc: 0.8453 - val_loss: 0.1122 - val_acc: 0.8453\n",
            "Epoch 379/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1144 - acc: 0.8564 - val_loss: 0.1114 - val_acc: 0.8619\n",
            "Epoch 380/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1265 - acc: 0.8177 - val_loss: 0.1113 - val_acc: 0.8508\n",
            "Epoch 381/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1156 - acc: 0.8343 - val_loss: 0.1111 - val_acc: 0.8508\n",
            "Epoch 382/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1121 - acc: 0.8674 - val_loss: 0.1110 - val_acc: 0.8508\n",
            "Epoch 383/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1158 - acc: 0.8453 - val_loss: 0.1116 - val_acc: 0.8564\n",
            "Epoch 384/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1163 - acc: 0.8453 - val_loss: 0.1112 - val_acc: 0.8619\n",
            "Epoch 385/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.8453 - val_loss: 0.1107 - val_acc: 0.8508\n",
            "Epoch 386/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1125 - acc: 0.8398 - val_loss: 0.1106 - val_acc: 0.8674\n",
            "Epoch 387/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1117 - acc: 0.8453 - val_loss: 0.1104 - val_acc: 0.8508\n",
            "Epoch 388/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1109 - acc: 0.8508 - val_loss: 0.1102 - val_acc: 0.8453\n",
            "Epoch 389/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.8508 - val_loss: 0.1101 - val_acc: 0.8453\n",
            "Epoch 390/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1116 - acc: 0.8564 - val_loss: 0.1101 - val_acc: 0.8564\n",
            "Epoch 391/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1133 - acc: 0.8398 - val_loss: 0.1103 - val_acc: 0.8619\n",
            "Epoch 392/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1128 - acc: 0.8398 - val_loss: 0.1104 - val_acc: 0.8619\n",
            "Epoch 393/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1119 - acc: 0.8287 - val_loss: 0.1107 - val_acc: 0.8564\n",
            "Epoch 394/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1112 - acc: 0.8564 - val_loss: 0.1097 - val_acc: 0.8564\n",
            "Epoch 395/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1098 - acc: 0.8453 - val_loss: 0.1105 - val_acc: 0.8564\n",
            "Epoch 396/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1118 - acc: 0.8398 - val_loss: 0.1104 - val_acc: 0.8508\n",
            "Epoch 397/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1111 - acc: 0.8564 - val_loss: 0.1102 - val_acc: 0.8564\n",
            "Epoch 398/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1120 - acc: 0.8453 - val_loss: 0.1090 - val_acc: 0.8508\n",
            "Epoch 399/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1109 - acc: 0.8508 - val_loss: 0.1106 - val_acc: 0.8564\n",
            "Epoch 400/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1115 - acc: 0.8398 - val_loss: 0.1098 - val_acc: 0.8674\n",
            "Epoch 401/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1101 - acc: 0.8453 - val_loss: 0.1091 - val_acc: 0.8564\n",
            "Epoch 402/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1141 - acc: 0.8453 - val_loss: 0.1116 - val_acc: 0.8398\n",
            "Epoch 403/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1114 - acc: 0.8564 - val_loss: 0.1106 - val_acc: 0.8453\n",
            "Epoch 404/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1091 - acc: 0.8564 - val_loss: 0.1117 - val_acc: 0.8398\n",
            "Epoch 405/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1139 - acc: 0.8453 - val_loss: 0.1101 - val_acc: 0.8508\n",
            "Epoch 406/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1196 - acc: 0.8398 - val_loss: 0.1123 - val_acc: 0.8398\n",
            "Epoch 407/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1153 - acc: 0.8453 - val_loss: 0.1162 - val_acc: 0.8398\n",
            "Epoch 408/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1181 - acc: 0.8177 - val_loss: 0.1087 - val_acc: 0.8674\n",
            "Epoch 409/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1139 - acc: 0.8508 - val_loss: 0.1084 - val_acc: 0.8674\n",
            "Epoch 410/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1202 - acc: 0.8287 - val_loss: 0.1079 - val_acc: 0.8453\n",
            "Epoch 411/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1112 - acc: 0.8564 - val_loss: 0.1079 - val_acc: 0.8674\n",
            "Epoch 412/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1093 - acc: 0.8453 - val_loss: 0.1086 - val_acc: 0.8619\n",
            "Epoch 413/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1090 - acc: 0.8453 - val_loss: 0.1084 - val_acc: 0.8674\n",
            "Epoch 414/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1091 - acc: 0.8564 - val_loss: 0.1088 - val_acc: 0.8564\n",
            "Epoch 415/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1085 - acc: 0.8619 - val_loss: 0.1081 - val_acc: 0.8674\n",
            "Epoch 416/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1129 - acc: 0.8398 - val_loss: 0.1071 - val_acc: 0.8564\n",
            "Epoch 417/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1087 - acc: 0.8508 - val_loss: 0.1069 - val_acc: 0.8564\n",
            "Epoch 418/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1081 - acc: 0.8619 - val_loss: 0.1069 - val_acc: 0.8564\n",
            "Epoch 419/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1090 - acc: 0.8564 - val_loss: 0.1068 - val_acc: 0.8508\n",
            "Epoch 420/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1074 - acc: 0.8619 - val_loss: 0.1067 - val_acc: 0.8453\n",
            "Epoch 421/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1074 - acc: 0.8564 - val_loss: 0.1066 - val_acc: 0.8398\n",
            "Epoch 422/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1077 - acc: 0.8508 - val_loss: 0.1064 - val_acc: 0.8508\n",
            "Epoch 423/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1117 - acc: 0.8564 - val_loss: 0.1066 - val_acc: 0.8508\n",
            "Epoch 424/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1094 - acc: 0.8508 - val_loss: 0.1063 - val_acc: 0.8453\n",
            "Epoch 425/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1103 - acc: 0.8564 - val_loss: 0.1075 - val_acc: 0.8619\n",
            "Epoch 426/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1070 - acc: 0.8564 - val_loss: 0.1063 - val_acc: 0.8508\n",
            "Epoch 427/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1077 - acc: 0.8674 - val_loss: 0.1062 - val_acc: 0.8674\n",
            "Epoch 428/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1093 - acc: 0.8619 - val_loss: 0.1068 - val_acc: 0.8674\n",
            "Epoch 429/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1081 - acc: 0.8398 - val_loss: 0.1057 - val_acc: 0.8453\n",
            "Epoch 430/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1117 - acc: 0.8398 - val_loss: 0.1059 - val_acc: 0.8508\n",
            "Epoch 431/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1124 - acc: 0.8343 - val_loss: 0.1063 - val_acc: 0.8564\n",
            "Epoch 432/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1095 - acc: 0.8453 - val_loss: 0.1066 - val_acc: 0.8619\n",
            "Epoch 433/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1049 - acc: 0.8564 - val_loss: 0.1081 - val_acc: 0.8508\n",
            "Epoch 434/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1115 - acc: 0.8398 - val_loss: 0.1080 - val_acc: 0.8619\n",
            "Epoch 435/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1138 - acc: 0.8564 - val_loss: 0.1114 - val_acc: 0.8453\n",
            "Epoch 436/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1094 - acc: 0.8674 - val_loss: 0.1068 - val_acc: 0.8619\n",
            "Epoch 437/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1082 - acc: 0.8398 - val_loss: 0.1057 - val_acc: 0.8619\n",
            "Epoch 438/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1090 - acc: 0.8453 - val_loss: 0.1047 - val_acc: 0.8619\n",
            "Epoch 439/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1061 - acc: 0.8508 - val_loss: 0.1047 - val_acc: 0.8508\n",
            "Epoch 440/1000\n",
            "12/12 [==============================] - 0s 16ms/step - loss: 0.1097 - acc: 0.8453 - val_loss: 0.1046 - val_acc: 0.8508\n",
            "Epoch 441/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1078 - acc: 0.8398 - val_loss: 0.1047 - val_acc: 0.8508\n",
            "Epoch 442/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1098 - acc: 0.8398 - val_loss: 0.1054 - val_acc: 0.8508\n",
            "Epoch 443/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1060 - acc: 0.8619 - val_loss: 0.1045 - val_acc: 0.8729\n",
            "Epoch 444/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1080 - acc: 0.8619 - val_loss: 0.1042 - val_acc: 0.8453\n",
            "Epoch 445/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1079 - acc: 0.8564 - val_loss: 0.1041 - val_acc: 0.8508\n",
            "Epoch 446/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1057 - acc: 0.8508 - val_loss: 0.1041 - val_acc: 0.8453\n",
            "Epoch 447/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1046 - acc: 0.8398 - val_loss: 0.1038 - val_acc: 0.8564\n",
            "Epoch 448/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.8729 - val_loss: 0.1047 - val_acc: 0.8508\n",
            "Epoch 449/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1075 - acc: 0.8674 - val_loss: 0.1075 - val_acc: 0.8508\n",
            "Epoch 450/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1080 - acc: 0.8508 - val_loss: 0.1068 - val_acc: 0.8564\n",
            "Epoch 451/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1069 - acc: 0.8674 - val_loss: 0.1065 - val_acc: 0.8564\n",
            "Epoch 452/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1067 - acc: 0.8564 - val_loss: 0.1041 - val_acc: 0.8508\n",
            "Epoch 453/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1066 - acc: 0.8508 - val_loss: 0.1033 - val_acc: 0.8564\n",
            "Epoch 454/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1090 - acc: 0.8619 - val_loss: 0.1061 - val_acc: 0.8508\n",
            "Epoch 455/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1055 - acc: 0.8674 - val_loss: 0.1031 - val_acc: 0.8674\n",
            "Epoch 456/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1041 - acc: 0.8453 - val_loss: 0.1034 - val_acc: 0.8508\n",
            "Epoch 457/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1034 - acc: 0.8564 - val_loss: 0.1033 - val_acc: 0.8729\n",
            "Epoch 458/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1041 - acc: 0.8508 - val_loss: 0.1029 - val_acc: 0.8729\n",
            "Epoch 459/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1061 - acc: 0.8619 - val_loss: 0.1030 - val_acc: 0.8508\n",
            "Epoch 460/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1137 - acc: 0.8453 - val_loss: 0.1080 - val_acc: 0.8564\n",
            "Epoch 461/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1078 - acc: 0.8564 - val_loss: 0.1063 - val_acc: 0.8619\n",
            "Epoch 462/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1112 - acc: 0.8287 - val_loss: 0.1041 - val_acc: 0.8674\n",
            "Epoch 463/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1092 - acc: 0.8398 - val_loss: 0.1076 - val_acc: 0.8674\n",
            "Epoch 464/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1062 - acc: 0.8674 - val_loss: 0.1024 - val_acc: 0.8729\n",
            "Epoch 465/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1056 - acc: 0.8674 - val_loss: 0.1048 - val_acc: 0.8619\n",
            "Epoch 466/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1043 - acc: 0.8564 - val_loss: 0.1036 - val_acc: 0.8619\n",
            "Epoch 467/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1037 - acc: 0.8564 - val_loss: 0.1022 - val_acc: 0.8729\n",
            "Epoch 468/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1050 - acc: 0.8674 - val_loss: 0.1032 - val_acc: 0.8564\n",
            "Epoch 469/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1068 - acc: 0.8453 - val_loss: 0.1119 - val_acc: 0.8453\n",
            "Epoch 470/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1120 - acc: 0.8453 - val_loss: 0.1018 - val_acc: 0.8674\n",
            "Epoch 471/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1060 - acc: 0.8619 - val_loss: 0.1060 - val_acc: 0.8674\n",
            "Epoch 472/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1067 - acc: 0.8343 - val_loss: 0.1040 - val_acc: 0.8674\n",
            "Epoch 473/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1077 - acc: 0.8619 - val_loss: 0.1016 - val_acc: 0.8564\n",
            "Epoch 474/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1041 - acc: 0.8564 - val_loss: 0.1037 - val_acc: 0.8619\n",
            "Epoch 475/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1069 - acc: 0.8508 - val_loss: 0.1021 - val_acc: 0.8729\n",
            "Epoch 476/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1026 - acc: 0.8453 - val_loss: 0.1017 - val_acc: 0.8508\n",
            "Epoch 477/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1071 - acc: 0.8619 - val_loss: 0.1016 - val_acc: 0.8564\n",
            "Epoch 478/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1034 - acc: 0.8564 - val_loss: 0.1015 - val_acc: 0.8508\n",
            "Epoch 479/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1092 - acc: 0.8453 - val_loss: 0.1047 - val_acc: 0.8674\n",
            "Epoch 480/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1065 - acc: 0.8619 - val_loss: 0.1067 - val_acc: 0.8674\n",
            "Epoch 481/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1079 - acc: 0.8674 - val_loss: 0.1054 - val_acc: 0.8674\n",
            "Epoch 482/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1032 - acc: 0.8674 - val_loss: 0.1023 - val_acc: 0.8564\n",
            "Epoch 483/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1143 - acc: 0.8287 - val_loss: 0.1064 - val_acc: 0.8564\n",
            "Epoch 484/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1123 - acc: 0.8564 - val_loss: 0.1025 - val_acc: 0.8619\n",
            "Epoch 485/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1047 - acc: 0.8619 - val_loss: 0.1007 - val_acc: 0.8674\n",
            "Epoch 486/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1048 - acc: 0.8508 - val_loss: 0.1004 - val_acc: 0.8619\n",
            "Epoch 487/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1024 - acc: 0.8619 - val_loss: 0.1006 - val_acc: 0.8729\n",
            "Epoch 488/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1041 - acc: 0.8619 - val_loss: 0.1008 - val_acc: 0.8564\n",
            "Epoch 489/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1019 - acc: 0.8619 - val_loss: 0.1024 - val_acc: 0.8674\n",
            "Epoch 490/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1068 - acc: 0.8508 - val_loss: 0.1080 - val_acc: 0.8564\n",
            "Epoch 491/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1021 - acc: 0.8729 - val_loss: 0.1029 - val_acc: 0.8674\n",
            "Epoch 492/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1103 - acc: 0.8508 - val_loss: 0.1020 - val_acc: 0.8674\n",
            "Epoch 493/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1014 - acc: 0.8508 - val_loss: 0.1011 - val_acc: 0.8619\n",
            "Epoch 494/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1107 - acc: 0.8619 - val_loss: 0.1010 - val_acc: 0.8619\n",
            "Epoch 495/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1057 - acc: 0.8564 - val_loss: 0.1083 - val_acc: 0.8508\n",
            "Epoch 496/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1156 - acc: 0.8453 - val_loss: 0.1025 - val_acc: 0.8674\n",
            "Epoch 497/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1117 - acc: 0.8453 - val_loss: 0.1007 - val_acc: 0.8674\n",
            "Epoch 498/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1084 - acc: 0.8453 - val_loss: 0.1010 - val_acc: 0.8674\n",
            "Epoch 499/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1023 - acc: 0.8619 - val_loss: 0.0994 - val_acc: 0.8619\n",
            "Epoch 500/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1006 - acc: 0.8674 - val_loss: 0.0994 - val_acc: 0.8619\n",
            "Epoch 501/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1008 - acc: 0.8674 - val_loss: 0.0992 - val_acc: 0.8564\n",
            "Epoch 502/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0997 - acc: 0.8619 - val_loss: 0.0992 - val_acc: 0.8619\n",
            "Epoch 503/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1004 - acc: 0.8674 - val_loss: 0.0991 - val_acc: 0.8564\n",
            "Epoch 504/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1026 - acc: 0.8619 - val_loss: 0.1020 - val_acc: 0.8674\n",
            "Epoch 505/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1017 - acc: 0.8619 - val_loss: 0.0999 - val_acc: 0.8674\n",
            "Epoch 506/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1034 - acc: 0.8729 - val_loss: 0.1007 - val_acc: 0.8729\n",
            "Epoch 507/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1037 - acc: 0.8619 - val_loss: 0.1016 - val_acc: 0.8674\n",
            "Epoch 508/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1039 - acc: 0.8674 - val_loss: 0.0987 - val_acc: 0.8674\n",
            "Epoch 509/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1061 - acc: 0.8564 - val_loss: 0.1002 - val_acc: 0.8674\n",
            "Epoch 510/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1148 - acc: 0.8287 - val_loss: 0.1031 - val_acc: 0.8674\n",
            "Epoch 511/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1092 - acc: 0.8453 - val_loss: 0.1006 - val_acc: 0.8674\n",
            "Epoch 512/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1068 - acc: 0.8619 - val_loss: 0.1127 - val_acc: 0.8453\n",
            "Epoch 513/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1087 - acc: 0.8785 - val_loss: 0.1048 - val_acc: 0.8619\n",
            "Epoch 514/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1084 - acc: 0.8564 - val_loss: 0.1055 - val_acc: 0.8564\n",
            "Epoch 515/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1105 - acc: 0.8453 - val_loss: 0.0984 - val_acc: 0.8729\n",
            "Epoch 516/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1013 - acc: 0.8619 - val_loss: 0.0989 - val_acc: 0.8674\n",
            "Epoch 517/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1003 - acc: 0.8729 - val_loss: 0.0981 - val_acc: 0.8674\n",
            "Epoch 518/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1052 - acc: 0.8619 - val_loss: 0.1017 - val_acc: 0.8729\n",
            "Epoch 519/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1046 - acc: 0.8729 - val_loss: 0.0984 - val_acc: 0.8674\n",
            "Epoch 520/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1100 - acc: 0.8453 - val_loss: 0.1005 - val_acc: 0.8785\n",
            "Epoch 521/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1043 - acc: 0.8674 - val_loss: 0.0988 - val_acc: 0.8729\n",
            "Epoch 522/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1007 - acc: 0.8674 - val_loss: 0.0979 - val_acc: 0.8619\n",
            "Epoch 523/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0995 - acc: 0.8564 - val_loss: 0.1001 - val_acc: 0.8785\n",
            "Epoch 524/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0988 - acc: 0.8729 - val_loss: 0.0982 - val_acc: 0.8729\n",
            "Epoch 525/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0997 - acc: 0.8729 - val_loss: 0.0977 - val_acc: 0.8619\n",
            "Epoch 526/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1058 - acc: 0.8619 - val_loss: 0.1016 - val_acc: 0.8674\n",
            "Epoch 527/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1247 - acc: 0.7845 - val_loss: 0.1073 - val_acc: 0.8453\n",
            "Epoch 528/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1304 - acc: 0.8287 - val_loss: 0.0978 - val_acc: 0.8619\n",
            "Epoch 529/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1140 - acc: 0.8398 - val_loss: 0.1033 - val_acc: 0.8729\n",
            "Epoch 530/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1117 - acc: 0.8453 - val_loss: 0.0981 - val_acc: 0.8729\n",
            "Epoch 531/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1022 - acc: 0.8674 - val_loss: 0.0977 - val_acc: 0.8619\n",
            "Epoch 532/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1125 - acc: 0.8453 - val_loss: 0.0978 - val_acc: 0.8674\n",
            "Epoch 533/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1003 - acc: 0.8619 - val_loss: 0.0991 - val_acc: 0.8729\n",
            "Epoch 534/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1091 - acc: 0.8398 - val_loss: 0.0996 - val_acc: 0.8674\n",
            "Epoch 535/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.1022 - acc: 0.8674 - val_loss: 0.1005 - val_acc: 0.8785\n",
            "Epoch 536/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.1006 - acc: 0.8729 - val_loss: 0.0980 - val_acc: 0.8729\n",
            "Epoch 537/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1006 - acc: 0.8729 - val_loss: 0.0971 - val_acc: 0.8729\n",
            "Epoch 538/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0995 - acc: 0.8619 - val_loss: 0.0974 - val_acc: 0.8785\n",
            "Epoch 539/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1003 - acc: 0.8619 - val_loss: 0.0973 - val_acc: 0.8674\n",
            "Epoch 540/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1093 - acc: 0.8343 - val_loss: 0.1001 - val_acc: 0.8674\n",
            "Epoch 541/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1026 - acc: 0.8619 - val_loss: 0.1027 - val_acc: 0.8674\n",
            "Epoch 542/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0989 - acc: 0.8729 - val_loss: 0.1004 - val_acc: 0.8619\n",
            "Epoch 543/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1043 - acc: 0.8729 - val_loss: 0.0973 - val_acc: 0.8785\n",
            "Epoch 544/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1063 - acc: 0.8564 - val_loss: 0.0980 - val_acc: 0.8729\n",
            "Epoch 545/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0984 - acc: 0.8729 - val_loss: 0.0964 - val_acc: 0.8619\n",
            "Epoch 546/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0968 - acc: 0.8785 - val_loss: 0.0963 - val_acc: 0.8619\n",
            "Epoch 547/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0969 - acc: 0.8619 - val_loss: 0.0969 - val_acc: 0.8729\n",
            "Epoch 548/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0974 - acc: 0.8785 - val_loss: 0.0963 - val_acc: 0.8674\n",
            "Epoch 549/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0986 - acc: 0.8729 - val_loss: 0.0977 - val_acc: 0.8674\n",
            "Epoch 550/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0994 - acc: 0.8564 - val_loss: 0.0960 - val_acc: 0.8729\n",
            "Epoch 551/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1018 - acc: 0.8564 - val_loss: 0.0964 - val_acc: 0.8785\n",
            "Epoch 552/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1104 - acc: 0.8453 - val_loss: 0.1014 - val_acc: 0.8674\n",
            "Epoch 553/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.1036 - acc: 0.8674 - val_loss: 0.1101 - val_acc: 0.8564\n",
            "Epoch 554/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1058 - acc: 0.8398 - val_loss: 0.1004 - val_acc: 0.8729\n",
            "Epoch 555/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8840 - val_loss: 0.1004 - val_acc: 0.8619\n",
            "Epoch 556/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0987 - acc: 0.8729 - val_loss: 0.0963 - val_acc: 0.8785\n",
            "Epoch 557/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0968 - acc: 0.8785 - val_loss: 0.0975 - val_acc: 0.8674\n",
            "Epoch 558/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0985 - acc: 0.8619 - val_loss: 0.0955 - val_acc: 0.8619\n",
            "Epoch 559/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1007 - acc: 0.8674 - val_loss: 0.0955 - val_acc: 0.8619\n",
            "Epoch 560/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0967 - acc: 0.8729 - val_loss: 0.0953 - val_acc: 0.8785\n",
            "Epoch 561/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0976 - acc: 0.8729 - val_loss: 0.0964 - val_acc: 0.8785\n",
            "Epoch 562/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1084 - acc: 0.8564 - val_loss: 0.0986 - val_acc: 0.8729\n",
            "Epoch 563/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0978 - acc: 0.8785 - val_loss: 0.0975 - val_acc: 0.8785\n",
            "Epoch 564/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0980 - acc: 0.8674 - val_loss: 0.0957 - val_acc: 0.8729\n",
            "Epoch 565/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0964 - acc: 0.8729 - val_loss: 0.0967 - val_acc: 0.8729\n",
            "Epoch 566/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1000 - acc: 0.8729 - val_loss: 0.0981 - val_acc: 0.8729\n",
            "Epoch 567/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0969 - acc: 0.8840 - val_loss: 0.1038 - val_acc: 0.8674\n",
            "Epoch 568/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1104 - acc: 0.8508 - val_loss: 0.0964 - val_acc: 0.8785\n",
            "Epoch 569/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0973 - acc: 0.8729 - val_loss: 0.1002 - val_acc: 0.8674\n",
            "Epoch 570/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.1014 - acc: 0.8785 - val_loss: 0.0977 - val_acc: 0.8729\n",
            "Epoch 571/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1002 - acc: 0.8674 - val_loss: 0.0950 - val_acc: 0.8785\n",
            "Epoch 572/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0986 - acc: 0.8729 - val_loss: 0.0969 - val_acc: 0.8729\n",
            "Epoch 573/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1107 - acc: 0.8453 - val_loss: 0.0987 - val_acc: 0.8674\n",
            "Epoch 574/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1046 - acc: 0.8674 - val_loss: 0.1057 - val_acc: 0.8619\n",
            "Epoch 575/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1163 - acc: 0.8343 - val_loss: 0.0991 - val_acc: 0.8619\n",
            "Epoch 576/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0971 - acc: 0.8785 - val_loss: 0.0957 - val_acc: 0.8785\n",
            "Epoch 577/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0993 - acc: 0.8674 - val_loss: 0.0944 - val_acc: 0.8785\n",
            "Epoch 578/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.8674 - val_loss: 0.0943 - val_acc: 0.8729\n",
            "Epoch 579/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0989 - acc: 0.8785 - val_loss: 0.0946 - val_acc: 0.8785\n",
            "Epoch 580/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0956 - acc: 0.8729 - val_loss: 0.0941 - val_acc: 0.8785\n",
            "Epoch 581/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0955 - acc: 0.8785 - val_loss: 0.0950 - val_acc: 0.8729\n",
            "Epoch 582/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0985 - acc: 0.8729 - val_loss: 0.0983 - val_acc: 0.8785\n",
            "Epoch 583/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0995 - acc: 0.8729 - val_loss: 0.0939 - val_acc: 0.8785\n",
            "Epoch 584/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.8729 - val_loss: 0.0949 - val_acc: 0.8785\n",
            "Epoch 585/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0965 - acc: 0.8729 - val_loss: 0.0942 - val_acc: 0.8785\n",
            "Epoch 586/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0962 - acc: 0.8785 - val_loss: 0.0940 - val_acc: 0.8785\n",
            "Epoch 587/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0959 - acc: 0.8564 - val_loss: 0.0971 - val_acc: 0.8785\n",
            "Epoch 588/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1033 - acc: 0.8674 - val_loss: 0.0968 - val_acc: 0.8729\n",
            "Epoch 589/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1018 - acc: 0.8674 - val_loss: 0.0973 - val_acc: 0.8785\n",
            "Epoch 590/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1028 - acc: 0.8508 - val_loss: 0.1046 - val_acc: 0.8619\n",
            "Epoch 591/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1018 - acc: 0.8785 - val_loss: 0.1011 - val_acc: 0.8729\n",
            "Epoch 592/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1012 - acc: 0.8619 - val_loss: 0.0935 - val_acc: 0.8729\n",
            "Epoch 593/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0945 - acc: 0.8729 - val_loss: 0.0939 - val_acc: 0.8785\n",
            "Epoch 594/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0980 - acc: 0.8453 - val_loss: 0.0942 - val_acc: 0.8729\n",
            "Epoch 595/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8729 - val_loss: 0.0932 - val_acc: 0.8840\n",
            "Epoch 596/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0969 - acc: 0.8729 - val_loss: 0.0933 - val_acc: 0.8729\n",
            "Epoch 597/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0949 - acc: 0.8785 - val_loss: 0.0934 - val_acc: 0.8785\n",
            "Epoch 598/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0958 - acc: 0.8840 - val_loss: 0.0928 - val_acc: 0.8840\n",
            "Epoch 599/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0936 - acc: 0.8729 - val_loss: 0.0933 - val_acc: 0.8840\n",
            "Epoch 600/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0994 - acc: 0.8729 - val_loss: 0.0944 - val_acc: 0.8785\n",
            "Epoch 601/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0953 - acc: 0.8729 - val_loss: 0.0928 - val_acc: 0.8729\n",
            "Epoch 602/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1035 - acc: 0.8508 - val_loss: 0.1006 - val_acc: 0.8729\n",
            "Epoch 603/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0984 - acc: 0.8785 - val_loss: 0.1000 - val_acc: 0.8619\n",
            "Epoch 604/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1006 - acc: 0.8619 - val_loss: 0.1039 - val_acc: 0.8619\n",
            "Epoch 605/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0986 - acc: 0.8619 - val_loss: 0.0937 - val_acc: 0.8840\n",
            "Epoch 606/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0977 - acc: 0.8674 - val_loss: 0.0925 - val_acc: 0.8895\n",
            "Epoch 607/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0938 - acc: 0.8840 - val_loss: 0.0927 - val_acc: 0.8785\n",
            "Epoch 608/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0944 - acc: 0.8840 - val_loss: 0.0934 - val_acc: 0.8840\n",
            "Epoch 609/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1003 - acc: 0.8564 - val_loss: 0.0924 - val_acc: 0.8729\n",
            "Epoch 610/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0952 - acc: 0.8674 - val_loss: 0.0921 - val_acc: 0.8785\n",
            "Epoch 611/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0927 - acc: 0.8785 - val_loss: 0.0920 - val_acc: 0.8895\n",
            "Epoch 612/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0970 - acc: 0.8729 - val_loss: 0.0955 - val_acc: 0.8840\n",
            "Epoch 613/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1102 - acc: 0.8398 - val_loss: 0.0925 - val_acc: 0.8785\n",
            "Epoch 614/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0990 - acc: 0.8729 - val_loss: 0.0944 - val_acc: 0.8729\n",
            "Epoch 615/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0926 - acc: 0.8895 - val_loss: 0.0934 - val_acc: 0.8729\n",
            "Epoch 616/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0951 - acc: 0.8619 - val_loss: 0.0924 - val_acc: 0.8840\n",
            "Epoch 617/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0931 - acc: 0.8895 - val_loss: 0.0917 - val_acc: 0.8895\n",
            "Epoch 618/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0933 - acc: 0.8950 - val_loss: 0.0944 - val_acc: 0.8729\n",
            "Epoch 619/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0958 - acc: 0.8729 - val_loss: 0.0915 - val_acc: 0.8895\n",
            "Epoch 620/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0959 - acc: 0.8785 - val_loss: 0.0944 - val_acc: 0.8840\n",
            "Epoch 621/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0987 - acc: 0.8674 - val_loss: 0.0956 - val_acc: 0.8674\n",
            "Epoch 622/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1083 - acc: 0.8453 - val_loss: 0.0964 - val_acc: 0.8840\n",
            "Epoch 623/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0978 - acc: 0.8950 - val_loss: 0.0912 - val_acc: 0.8785\n",
            "Epoch 624/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1019 - acc: 0.8729 - val_loss: 0.0935 - val_acc: 0.8729\n",
            "Epoch 625/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1063 - acc: 0.8508 - val_loss: 0.1011 - val_acc: 0.8729\n",
            "Epoch 626/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0996 - acc: 0.8564 - val_loss: 0.0919 - val_acc: 0.8785\n",
            "Epoch 627/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0924 - acc: 0.8785 - val_loss: 0.0920 - val_acc: 0.8840\n",
            "Epoch 628/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.8619 - val_loss: 0.0926 - val_acc: 0.8840\n",
            "Epoch 629/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0971 - acc: 0.8729 - val_loss: 0.0913 - val_acc: 0.8895\n",
            "Epoch 630/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1033 - acc: 0.8729 - val_loss: 0.0941 - val_acc: 0.8785\n",
            "Epoch 631/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0949 - acc: 0.8840 - val_loss: 0.0908 - val_acc: 0.8785\n",
            "Epoch 632/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8674 - val_loss: 0.0907 - val_acc: 0.8895\n",
            "Epoch 633/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0918 - acc: 0.8840 - val_loss: 0.0906 - val_acc: 0.8895\n",
            "Epoch 634/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0923 - acc: 0.8950 - val_loss: 0.0906 - val_acc: 0.8785\n",
            "Epoch 635/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0911 - acc: 0.8840 - val_loss: 0.0907 - val_acc: 0.8785\n",
            "Epoch 636/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0911 - acc: 0.8729 - val_loss: 0.0905 - val_acc: 0.8895\n",
            "Epoch 637/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0934 - acc: 0.8840 - val_loss: 0.0939 - val_acc: 0.8674\n",
            "Epoch 638/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1034 - acc: 0.8564 - val_loss: 0.0946 - val_acc: 0.8840\n",
            "Epoch 639/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1001 - acc: 0.8619 - val_loss: 0.0902 - val_acc: 0.8840\n",
            "Epoch 640/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0954 - acc: 0.8840 - val_loss: 0.0908 - val_acc: 0.8895\n",
            "Epoch 641/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0929 - acc: 0.8895 - val_loss: 0.0938 - val_acc: 0.8785\n",
            "Epoch 642/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0909 - acc: 0.8950 - val_loss: 0.0912 - val_acc: 0.8840\n",
            "Epoch 643/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0931 - acc: 0.8785 - val_loss: 0.0900 - val_acc: 0.8785\n",
            "Epoch 644/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.8840 - val_loss: 0.0900 - val_acc: 0.8785\n",
            "Epoch 645/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0947 - acc: 0.8729 - val_loss: 0.0924 - val_acc: 0.8840\n",
            "Epoch 646/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0992 - acc: 0.8674 - val_loss: 0.0918 - val_acc: 0.8785\n",
            "Epoch 647/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0964 - acc: 0.8508 - val_loss: 0.0921 - val_acc: 0.8895\n",
            "Epoch 648/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0937 - acc: 0.8785 - val_loss: 0.0906 - val_acc: 0.8840\n",
            "Epoch 649/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0940 - acc: 0.8729 - val_loss: 0.0898 - val_acc: 0.8785\n",
            "Epoch 650/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1009 - acc: 0.8619 - val_loss: 0.0905 - val_acc: 0.8895\n",
            "Epoch 651/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0913 - acc: 0.8840 - val_loss: 0.0897 - val_acc: 0.8785\n",
            "Epoch 652/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0971 - acc: 0.8729 - val_loss: 0.0935 - val_acc: 0.8729\n",
            "Epoch 653/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0910 - acc: 0.8840 - val_loss: 0.0932 - val_acc: 0.8895\n",
            "Epoch 654/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0942 - acc: 0.9006 - val_loss: 0.1033 - val_acc: 0.8619\n",
            "Epoch 655/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1027 - acc: 0.8729 - val_loss: 0.0928 - val_acc: 0.8840\n",
            "Epoch 656/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0911 - acc: 0.8785 - val_loss: 0.0909 - val_acc: 0.8785\n",
            "Epoch 657/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.8785 - val_loss: 0.0901 - val_acc: 0.8840\n",
            "Epoch 658/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0899 - acc: 0.8840 - val_loss: 0.0892 - val_acc: 0.8895\n",
            "Epoch 659/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0937 - acc: 0.8895 - val_loss: 0.0902 - val_acc: 0.8895\n",
            "Epoch 660/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0894 - acc: 0.8895 - val_loss: 0.0910 - val_acc: 0.8895\n",
            "Epoch 661/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0929 - acc: 0.8895 - val_loss: 0.0899 - val_acc: 0.8895\n",
            "Epoch 662/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0956 - acc: 0.8840 - val_loss: 0.0897 - val_acc: 0.8895\n",
            "Epoch 663/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0931 - acc: 0.8785 - val_loss: 0.0903 - val_acc: 0.8840\n",
            "Epoch 664/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0907 - acc: 0.8840 - val_loss: 0.0930 - val_acc: 0.8895\n",
            "Epoch 665/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0966 - acc: 0.8840 - val_loss: 0.0890 - val_acc: 0.8895\n",
            "Epoch 666/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.8785 - val_loss: 0.0936 - val_acc: 0.8840\n",
            "Epoch 667/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0944 - acc: 0.8895 - val_loss: 0.0886 - val_acc: 0.8840\n",
            "Epoch 668/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0936 - acc: 0.8785 - val_loss: 0.0920 - val_acc: 0.8674\n",
            "Epoch 669/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0980 - acc: 0.8729 - val_loss: 0.0889 - val_acc: 0.8840\n",
            "Epoch 670/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0914 - acc: 0.8785 - val_loss: 0.0898 - val_acc: 0.8895\n",
            "Epoch 671/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.8950 - val_loss: 0.0885 - val_acc: 0.8785\n",
            "Epoch 672/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0910 - acc: 0.8785 - val_loss: 0.0935 - val_acc: 0.8785\n",
            "Epoch 673/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0950 - acc: 0.8729 - val_loss: 0.0908 - val_acc: 0.8895\n",
            "Epoch 674/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0923 - acc: 0.8950 - val_loss: 0.0909 - val_acc: 0.8674\n",
            "Epoch 675/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0916 - acc: 0.8785 - val_loss: 0.0916 - val_acc: 0.8840\n",
            "Epoch 676/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0926 - acc: 0.8729 - val_loss: 0.0880 - val_acc: 0.8895\n",
            "Epoch 677/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.8840 - val_loss: 0.0899 - val_acc: 0.8840\n",
            "Epoch 678/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - acc: 0.8895 - val_loss: 0.0884 - val_acc: 0.8950\n",
            "Epoch 679/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0910 - acc: 0.8895 - val_loss: 0.0877 - val_acc: 0.8895\n",
            "Epoch 680/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0887 - acc: 0.8895 - val_loss: 0.0880 - val_acc: 0.8840\n",
            "Epoch 681/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0898 - acc: 0.8840 - val_loss: 0.0877 - val_acc: 0.8895\n",
            "Epoch 682/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0893 - acc: 0.8729 - val_loss: 0.0877 - val_acc: 0.8840\n",
            "Epoch 683/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0902 - acc: 0.8840 - val_loss: 0.0880 - val_acc: 0.8895\n",
            "Epoch 684/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0892 - acc: 0.8840 - val_loss: 0.0890 - val_acc: 0.8895\n",
            "Epoch 685/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0894 - acc: 0.8785 - val_loss: 0.0874 - val_acc: 0.8895\n",
            "Epoch 686/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - acc: 0.8895 - val_loss: 0.0874 - val_acc: 0.8840\n",
            "Epoch 687/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0922 - acc: 0.8950 - val_loss: 0.0887 - val_acc: 0.8895\n",
            "Epoch 688/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0885 - acc: 0.8840 - val_loss: 0.0873 - val_acc: 0.8895\n",
            "Epoch 689/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - acc: 0.8950 - val_loss: 0.0874 - val_acc: 0.8785\n",
            "Epoch 690/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0884 - acc: 0.8895 - val_loss: 0.0877 - val_acc: 0.8840\n",
            "Epoch 691/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0916 - acc: 0.8895 - val_loss: 0.0876 - val_acc: 0.8950\n",
            "Epoch 692/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0899 - acc: 0.8895 - val_loss: 0.0870 - val_acc: 0.8895\n",
            "Epoch 693/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0960 - acc: 0.8619 - val_loss: 0.0882 - val_acc: 0.8950\n",
            "Epoch 694/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0884 - acc: 0.8950 - val_loss: 0.0868 - val_acc: 0.8895\n",
            "Epoch 695/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0886 - acc: 0.8785 - val_loss: 0.0904 - val_acc: 0.8785\n",
            "Epoch 696/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0913 - acc: 0.8840 - val_loss: 0.0870 - val_acc: 0.8840\n",
            "Epoch 697/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0887 - acc: 0.8895 - val_loss: 0.0866 - val_acc: 0.8895\n",
            "Epoch 698/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8840 - val_loss: 0.0866 - val_acc: 0.8950\n",
            "Epoch 699/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0887 - acc: 0.8840 - val_loss: 0.0888 - val_acc: 0.8895\n",
            "Epoch 700/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0905 - acc: 0.8840 - val_loss: 0.0865 - val_acc: 0.8950\n",
            "Epoch 701/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0876 - acc: 0.8950 - val_loss: 0.0868 - val_acc: 0.8950\n",
            "Epoch 702/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0879 - acc: 0.8840 - val_loss: 0.0869 - val_acc: 0.8950\n",
            "Epoch 703/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0886 - acc: 0.8950 - val_loss: 0.0868 - val_acc: 0.8950\n",
            "Epoch 704/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0926 - acc: 0.8840 - val_loss: 0.0888 - val_acc: 0.8895\n",
            "Epoch 705/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0881 - acc: 0.8895 - val_loss: 0.0863 - val_acc: 0.8895\n",
            "Epoch 706/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0910 - acc: 0.8840 - val_loss: 0.0863 - val_acc: 0.8895\n",
            "Epoch 707/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0927 - acc: 0.8729 - val_loss: 0.0887 - val_acc: 0.8785\n",
            "Epoch 708/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0881 - acc: 0.8895 - val_loss: 0.0861 - val_acc: 0.8895\n",
            "Epoch 709/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0897 - acc: 0.8895 - val_loss: 0.0887 - val_acc: 0.8895\n",
            "Epoch 710/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0877 - acc: 0.9006 - val_loss: 0.0863 - val_acc: 0.8950\n",
            "Epoch 711/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0892 - acc: 0.8840 - val_loss: 0.0861 - val_acc: 0.8950\n",
            "Epoch 712/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0903 - acc: 0.8840 - val_loss: 0.0933 - val_acc: 0.8895\n",
            "Epoch 713/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0944 - acc: 0.8895 - val_loss: 0.0913 - val_acc: 0.8729\n",
            "Epoch 714/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0899 - acc: 0.8729 - val_loss: 0.0961 - val_acc: 0.8840\n",
            "Epoch 715/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0890 - acc: 0.8840 - val_loss: 0.1071 - val_acc: 0.8564\n",
            "Epoch 716/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1063 - acc: 0.8287 - val_loss: 0.0882 - val_acc: 0.8895\n",
            "Epoch 717/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0866 - acc: 0.8729 - val_loss: 0.0876 - val_acc: 0.8785\n",
            "Epoch 718/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0896 - acc: 0.8895 - val_loss: 0.0874 - val_acc: 0.8840\n",
            "Epoch 719/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0876 - acc: 0.8895 - val_loss: 0.0857 - val_acc: 0.8895\n",
            "Epoch 720/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0869 - acc: 0.8840 - val_loss: 0.0887 - val_acc: 0.8840\n",
            "Epoch 721/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0871 - acc: 0.9006 - val_loss: 0.0875 - val_acc: 0.8895\n",
            "Epoch 722/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8895 - val_loss: 0.0859 - val_acc: 0.8950\n",
            "Epoch 723/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0933 - acc: 0.8785 - val_loss: 0.1077 - val_acc: 0.8508\n",
            "Epoch 724/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1061 - acc: 0.8508 - val_loss: 0.0963 - val_acc: 0.8729\n",
            "Epoch 725/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0933 - acc: 0.8950 - val_loss: 0.0861 - val_acc: 0.8785\n",
            "Epoch 726/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0882 - acc: 0.8895 - val_loss: 0.0857 - val_acc: 0.8840\n",
            "Epoch 727/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0932 - acc: 0.8785 - val_loss: 0.0910 - val_acc: 0.8729\n",
            "Epoch 728/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0909 - acc: 0.8950 - val_loss: 0.0912 - val_acc: 0.8895\n",
            "Epoch 729/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0902 - acc: 0.8564 - val_loss: 0.0884 - val_acc: 0.8840\n",
            "Epoch 730/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0857 - acc: 0.8840 - val_loss: 0.0859 - val_acc: 0.8785\n",
            "Epoch 731/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0866 - acc: 0.8785 - val_loss: 0.0864 - val_acc: 0.8950\n",
            "Epoch 732/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.8895 - val_loss: 0.0949 - val_acc: 0.8840\n",
            "Epoch 733/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0981 - acc: 0.8619 - val_loss: 0.0989 - val_acc: 0.8619\n",
            "Epoch 734/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0990 - acc: 0.8453 - val_loss: 0.0994 - val_acc: 0.8674\n",
            "Epoch 735/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0932 - acc: 0.8619 - val_loss: 0.0954 - val_acc: 0.8729\n",
            "Epoch 736/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0963 - acc: 0.8674 - val_loss: 0.0850 - val_acc: 0.8895\n",
            "Epoch 737/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0858 - acc: 0.8840 - val_loss: 0.0847 - val_acc: 0.8950\n",
            "Epoch 738/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0887 - acc: 0.8895 - val_loss: 0.0851 - val_acc: 0.8950\n",
            "Epoch 739/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8785 - val_loss: 0.0847 - val_acc: 0.8895\n",
            "Epoch 740/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0879 - acc: 0.8785 - val_loss: 0.0887 - val_acc: 0.8785\n",
            "Epoch 741/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0895 - acc: 0.8785 - val_loss: 0.0845 - val_acc: 0.8895\n",
            "Epoch 742/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - acc: 0.8785 - val_loss: 0.0890 - val_acc: 0.8840\n",
            "Epoch 743/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0872 - acc: 0.8895 - val_loss: 0.0844 - val_acc: 0.8950\n",
            "Epoch 744/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0874 - acc: 0.8895 - val_loss: 0.0887 - val_acc: 0.8840\n",
            "Epoch 745/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8950 - val_loss: 0.0852 - val_acc: 0.8950\n",
            "Epoch 746/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0869 - acc: 0.8895 - val_loss: 0.0846 - val_acc: 0.8950\n",
            "Epoch 747/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0863 - acc: 0.8840 - val_loss: 0.0842 - val_acc: 0.8950\n",
            "Epoch 748/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0868 - acc: 0.9006 - val_loss: 0.0857 - val_acc: 0.8895\n",
            "Epoch 749/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0863 - acc: 0.8729 - val_loss: 0.0841 - val_acc: 0.8950\n",
            "Epoch 750/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0856 - acc: 0.8950 - val_loss: 0.0878 - val_acc: 0.8895\n",
            "Epoch 751/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.9006 - val_loss: 0.0839 - val_acc: 0.8895\n",
            "Epoch 752/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0869 - acc: 0.8895 - val_loss: 0.0862 - val_acc: 0.8895\n",
            "Epoch 753/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - acc: 0.8895 - val_loss: 0.0839 - val_acc: 0.8950\n",
            "Epoch 754/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0895 - acc: 0.8895 - val_loss: 0.0902 - val_acc: 0.8895\n",
            "Epoch 755/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0881 - acc: 0.9061 - val_loss: 0.0913 - val_acc: 0.8785\n",
            "Epoch 756/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0928 - acc: 0.8619 - val_loss: 0.0866 - val_acc: 0.8895\n",
            "Epoch 757/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.8840 - val_loss: 0.0840 - val_acc: 0.8840\n",
            "Epoch 758/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0864 - acc: 0.8895 - val_loss: 0.0837 - val_acc: 0.8950\n",
            "Epoch 759/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0855 - acc: 0.8895 - val_loss: 0.0839 - val_acc: 0.8950\n",
            "Epoch 760/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0878 - acc: 0.8895 - val_loss: 0.0838 - val_acc: 0.9006\n",
            "Epoch 761/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0895 - acc: 0.8674 - val_loss: 0.0836 - val_acc: 0.8895\n",
            "Epoch 762/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.8950 - val_loss: 0.0863 - val_acc: 0.8895\n",
            "Epoch 763/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0863 - acc: 0.8950 - val_loss: 0.0833 - val_acc: 0.8950\n",
            "Epoch 764/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0859 - acc: 0.8895 - val_loss: 0.0843 - val_acc: 0.8950\n",
            "Epoch 765/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0904 - acc: 0.8895 - val_loss: 0.0974 - val_acc: 0.8619\n",
            "Epoch 766/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0926 - acc: 0.8674 - val_loss: 0.0854 - val_acc: 0.8895\n",
            "Epoch 767/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0893 - acc: 0.8895 - val_loss: 0.0849 - val_acc: 0.8950\n",
            "Epoch 768/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0917 - acc: 0.8729 - val_loss: 0.0930 - val_acc: 0.8785\n",
            "Epoch 769/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1031 - acc: 0.8564 - val_loss: 0.0904 - val_acc: 0.8895\n",
            "Epoch 770/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0869 - acc: 0.8840 - val_loss: 0.0838 - val_acc: 0.9006\n",
            "Epoch 771/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0844 - acc: 0.8895 - val_loss: 0.0831 - val_acc: 0.8950\n",
            "Epoch 772/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0846 - acc: 0.8895 - val_loss: 0.0839 - val_acc: 0.8840\n",
            "Epoch 773/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.8950 - val_loss: 0.0892 - val_acc: 0.8785\n",
            "Epoch 774/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.8950 - val_loss: 0.0877 - val_acc: 0.8895\n",
            "Epoch 775/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0842 - acc: 0.8895 - val_loss: 0.0828 - val_acc: 0.8950\n",
            "Epoch 776/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0885 - acc: 0.8895 - val_loss: 0.0858 - val_acc: 0.8895\n",
            "Epoch 777/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0860 - acc: 0.9061 - val_loss: 0.0896 - val_acc: 0.8895\n",
            "Epoch 778/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0845 - acc: 0.8950 - val_loss: 0.0916 - val_acc: 0.8840\n",
            "Epoch 779/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1016 - acc: 0.8508 - val_loss: 0.0915 - val_acc: 0.8895\n",
            "Epoch 780/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0891 - acc: 0.8785 - val_loss: 0.0834 - val_acc: 0.8895\n",
            "Epoch 781/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - acc: 0.8950 - val_loss: 0.0893 - val_acc: 0.8785\n",
            "Epoch 782/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1089 - acc: 0.8343 - val_loss: 0.1042 - val_acc: 0.8564\n",
            "Epoch 783/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.8840 - val_loss: 0.0858 - val_acc: 0.8950\n",
            "Epoch 784/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0887 - acc: 0.8895 - val_loss: 0.0994 - val_acc: 0.8674\n",
            "Epoch 785/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0906 - acc: 0.8840 - val_loss: 0.0884 - val_acc: 0.8840\n",
            "Epoch 786/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0864 - acc: 0.8729 - val_loss: 0.0837 - val_acc: 0.8895\n",
            "Epoch 787/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0946 - acc: 0.8785 - val_loss: 0.0840 - val_acc: 0.8895\n",
            "Epoch 788/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1029 - acc: 0.8564 - val_loss: 0.0877 - val_acc: 0.8840\n",
            "Epoch 789/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0842 - acc: 0.8950 - val_loss: 0.0867 - val_acc: 0.8895\n",
            "Epoch 790/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0862 - acc: 0.8840 - val_loss: 0.0832 - val_acc: 0.9006\n",
            "Epoch 791/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0843 - acc: 0.8950 - val_loss: 0.0824 - val_acc: 0.8840\n",
            "Epoch 792/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0840 - acc: 0.8895 - val_loss: 0.0823 - val_acc: 0.8895\n",
            "Epoch 793/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0839 - acc: 0.8785 - val_loss: 0.0827 - val_acc: 0.8950\n",
            "Epoch 794/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0896 - acc: 0.8895 - val_loss: 0.0822 - val_acc: 0.9006\n",
            "Epoch 795/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0857 - acc: 0.8950 - val_loss: 0.0851 - val_acc: 0.8895\n",
            "Epoch 796/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0854 - acc: 0.8840 - val_loss: 0.0861 - val_acc: 0.8895\n",
            "Epoch 797/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0877 - acc: 0.9006 - val_loss: 0.0837 - val_acc: 0.8950\n",
            "Epoch 798/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - acc: 0.8785 - val_loss: 0.0825 - val_acc: 0.8895\n",
            "Epoch 799/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0833 - acc: 0.8950 - val_loss: 0.0820 - val_acc: 0.8895\n",
            "Epoch 800/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0823 - acc: 0.8950 - val_loss: 0.0819 - val_acc: 0.8950\n",
            "Epoch 801/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0841 - acc: 0.8895 - val_loss: 0.0819 - val_acc: 0.8895\n",
            "Epoch 802/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0850 - acc: 0.8895 - val_loss: 0.0825 - val_acc: 0.9061\n",
            "Epoch 803/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0832 - acc: 0.8950 - val_loss: 0.0818 - val_acc: 0.9006\n",
            "Epoch 804/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0839 - acc: 0.8895 - val_loss: 0.0832 - val_acc: 0.9006\n",
            "Epoch 805/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0884 - acc: 0.8785 - val_loss: 0.0945 - val_acc: 0.8840\n",
            "Epoch 806/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1039 - acc: 0.8674 - val_loss: 0.0857 - val_acc: 0.8895\n",
            "Epoch 807/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8840 - val_loss: 0.1093 - val_acc: 0.8398\n",
            "Epoch 808/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1180 - acc: 0.8287 - val_loss: 0.0970 - val_acc: 0.8674\n",
            "Epoch 809/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8564 - val_loss: 0.0925 - val_acc: 0.8895\n",
            "Epoch 810/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0814 - acc: 0.9006 - val_loss: 0.0956 - val_acc: 0.8674\n",
            "Epoch 811/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - acc: 0.8729 - val_loss: 0.0823 - val_acc: 0.8840\n",
            "Epoch 812/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0865 - acc: 0.8950 - val_loss: 0.0863 - val_acc: 0.8840\n",
            "Epoch 813/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0864 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8895\n",
            "Epoch 814/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0875 - acc: 0.8895 - val_loss: 0.0815 - val_acc: 0.8895\n",
            "Epoch 815/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0829 - acc: 0.8895 - val_loss: 0.0829 - val_acc: 0.9006\n",
            "Epoch 816/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0931 - acc: 0.8619 - val_loss: 0.0937 - val_acc: 0.8840\n",
            "Epoch 817/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0859 - acc: 0.8785 - val_loss: 0.0833 - val_acc: 0.8950\n",
            "Epoch 818/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0870 - acc: 0.8785 - val_loss: 0.0818 - val_acc: 0.8950\n",
            "Epoch 819/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0876 - acc: 0.8895 - val_loss: 0.0875 - val_acc: 0.8895\n",
            "Epoch 820/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0841 - acc: 0.8950 - val_loss: 0.0868 - val_acc: 0.8785\n",
            "Epoch 821/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0983 - acc: 0.8729 - val_loss: 0.0896 - val_acc: 0.8895\n",
            "Epoch 822/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0850 - acc: 0.8950 - val_loss: 0.0829 - val_acc: 0.8950\n",
            "Epoch 823/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0842 - acc: 0.8895 - val_loss: 0.0811 - val_acc: 0.9061\n",
            "Epoch 824/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0828 - acc: 0.9006 - val_loss: 0.0814 - val_acc: 0.9061\n",
            "Epoch 825/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.8840 - val_loss: 0.0824 - val_acc: 0.8895\n",
            "Epoch 826/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0826 - acc: 0.8950 - val_loss: 0.0811 - val_acc: 0.8950\n",
            "Epoch 827/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0834 - acc: 0.9006 - val_loss: 0.0861 - val_acc: 0.8785\n",
            "Epoch 828/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.8840 - val_loss: 0.0850 - val_acc: 0.8895\n",
            "Epoch 829/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0825 - acc: 0.8895 - val_loss: 0.0829 - val_acc: 0.8950\n",
            "Epoch 830/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0823 - acc: 0.8950 - val_loss: 0.0843 - val_acc: 0.8895\n",
            "Epoch 831/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0842 - acc: 0.8785 - val_loss: 0.0808 - val_acc: 0.8950\n",
            "Epoch 832/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.9006 - val_loss: 0.0808 - val_acc: 0.8950\n",
            "Epoch 833/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0820 - acc: 0.8950 - val_loss: 0.0822 - val_acc: 0.9061\n",
            "Epoch 834/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0827 - acc: 0.9061 - val_loss: 0.0853 - val_acc: 0.8895\n",
            "Epoch 835/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0826 - acc: 0.8950 - val_loss: 0.0834 - val_acc: 0.9006\n",
            "Epoch 836/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0861 - acc: 0.8729 - val_loss: 0.0815 - val_acc: 0.8950\n",
            "Epoch 837/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0819 - acc: 0.9006 - val_loss: 0.0806 - val_acc: 0.9006\n",
            "Epoch 838/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0851 - acc: 0.8950 - val_loss: 0.0861 - val_acc: 0.8840\n",
            "Epoch 839/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0896 - acc: 0.8950 - val_loss: 0.0869 - val_acc: 0.8950\n",
            "Epoch 840/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0889 - acc: 0.8895 - val_loss: 0.0890 - val_acc: 0.8785\n",
            "Epoch 841/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0843 - acc: 0.8895 - val_loss: 0.0808 - val_acc: 0.8950\n",
            "Epoch 842/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0824 - acc: 0.8840 - val_loss: 0.0809 - val_acc: 0.9006\n",
            "Epoch 843/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0842 - acc: 0.8950 - val_loss: 0.0829 - val_acc: 0.8950\n",
            "Epoch 844/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0898 - acc: 0.8785 - val_loss: 0.0814 - val_acc: 0.9061\n",
            "Epoch 845/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0835 - acc: 0.8895 - val_loss: 0.0842 - val_acc: 0.8895\n",
            "Epoch 846/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0836 - acc: 0.8840 - val_loss: 0.0852 - val_acc: 0.8895\n",
            "Epoch 847/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0872 - acc: 0.8840 - val_loss: 0.0814 - val_acc: 0.9006\n",
            "Epoch 848/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0888 - acc: 0.8785 - val_loss: 0.0818 - val_acc: 0.8950\n",
            "Epoch 849/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0906 - acc: 0.8729 - val_loss: 0.0816 - val_acc: 0.8950\n",
            "Epoch 850/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0813 - acc: 0.8895 - val_loss: 0.0870 - val_acc: 0.8785\n",
            "Epoch 851/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0871 - acc: 0.8840 - val_loss: 0.0842 - val_acc: 0.8895\n",
            "Epoch 852/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0823 - acc: 0.8950 - val_loss: 0.0831 - val_acc: 0.8950\n",
            "Epoch 853/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0904 - acc: 0.8895 - val_loss: 0.0825 - val_acc: 0.9006\n",
            "Epoch 854/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0870 - acc: 0.8840 - val_loss: 0.0802 - val_acc: 0.8950\n",
            "Epoch 855/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0830 - acc: 0.8785 - val_loss: 0.0818 - val_acc: 0.8950\n",
            "Epoch 856/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0855 - acc: 0.9006 - val_loss: 0.0815 - val_acc: 0.9061\n",
            "Epoch 857/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0822 - acc: 0.9061 - val_loss: 0.0799 - val_acc: 0.9006\n",
            "Epoch 858/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0838 - acc: 0.9006 - val_loss: 0.0799 - val_acc: 0.9061\n",
            "Epoch 859/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 0.9061 - val_loss: 0.0917 - val_acc: 0.8840\n",
            "Epoch 860/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8729 - val_loss: 0.0838 - val_acc: 0.9006\n",
            "Epoch 861/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0850 - acc: 0.9006 - val_loss: 0.0813 - val_acc: 0.8950\n",
            "Epoch 862/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0801 - acc: 0.9006 - val_loss: 0.0826 - val_acc: 0.9006\n",
            "Epoch 863/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0820 - acc: 0.9061 - val_loss: 0.0797 - val_acc: 0.9006\n",
            "Epoch 864/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0825 - acc: 0.9006 - val_loss: 0.0796 - val_acc: 0.9006\n",
            "Epoch 865/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0814 - acc: 0.9116 - val_loss: 0.0809 - val_acc: 0.8950\n",
            "Epoch 866/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0823 - acc: 0.8895 - val_loss: 0.0796 - val_acc: 0.9006\n",
            "Epoch 867/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0823 - acc: 0.9061 - val_loss: 0.0877 - val_acc: 0.8785\n",
            "Epoch 868/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0849 - acc: 0.8895 - val_loss: 0.0851 - val_acc: 0.8895\n",
            "Epoch 869/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0847 - acc: 0.8895 - val_loss: 0.0795 - val_acc: 0.9006\n",
            "Epoch 870/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0832 - acc: 0.8950 - val_loss: 0.0891 - val_acc: 0.8785\n",
            "Epoch 871/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0848 - acc: 0.8785 - val_loss: 0.0824 - val_acc: 0.8950\n",
            "Epoch 872/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0784 - acc: 0.9061 - val_loss: 0.0826 - val_acc: 0.9061\n",
            "Epoch 873/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0839 - acc: 0.8950 - val_loss: 0.0965 - val_acc: 0.8785\n",
            "Epoch 874/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0857 - acc: 0.9006 - val_loss: 0.0822 - val_acc: 0.9061\n",
            "Epoch 875/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0845 - acc: 0.9061 - val_loss: 0.0796 - val_acc: 0.9061\n",
            "Epoch 876/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0821 - acc: 0.9006 - val_loss: 0.0793 - val_acc: 0.9006\n",
            "Epoch 877/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0813 - acc: 0.8895 - val_loss: 0.0799 - val_acc: 0.9006\n",
            "Epoch 878/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0852 - acc: 0.8950 - val_loss: 0.0845 - val_acc: 0.8895\n",
            "Epoch 879/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0903 - acc: 0.8785 - val_loss: 0.0889 - val_acc: 0.8729\n",
            "Epoch 880/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0992 - acc: 0.8564 - val_loss: 0.0880 - val_acc: 0.8895\n",
            "Epoch 881/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0835 - acc: 0.9006 - val_loss: 0.0793 - val_acc: 0.9061\n",
            "Epoch 882/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0836 - acc: 0.8950 - val_loss: 0.0790 - val_acc: 0.9006\n",
            "Epoch 883/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0811 - acc: 0.8840 - val_loss: 0.0813 - val_acc: 0.8950\n",
            "Epoch 884/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0818 - acc: 0.9006 - val_loss: 0.0801 - val_acc: 0.9006\n",
            "Epoch 885/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0818 - acc: 0.8840 - val_loss: 0.0792 - val_acc: 0.9061\n",
            "Epoch 886/1000\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0866 - acc: 0.8950 - val_loss: 0.0885 - val_acc: 0.8895\n",
            "Epoch 887/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0898 - acc: 0.8785 - val_loss: 0.0821 - val_acc: 0.9061\n",
            "Epoch 888/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0811 - acc: 0.8950 - val_loss: 0.0789 - val_acc: 0.9061\n",
            "Epoch 889/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0799 - acc: 0.8950 - val_loss: 0.0796 - val_acc: 0.9061\n",
            "Epoch 890/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0803 - acc: 0.8950 - val_loss: 0.0789 - val_acc: 0.9061\n",
            "Epoch 891/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0803 - acc: 0.8950 - val_loss: 0.0789 - val_acc: 0.9006\n",
            "Epoch 892/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0825 - acc: 0.8895 - val_loss: 0.0805 - val_acc: 0.8950\n",
            "Epoch 893/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0801 - acc: 0.8950 - val_loss: 0.0805 - val_acc: 0.9006\n",
            "Epoch 894/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0836 - acc: 0.9006 - val_loss: 0.0821 - val_acc: 0.9061\n",
            "Epoch 895/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0838 - acc: 0.8950 - val_loss: 0.0793 - val_acc: 0.9061\n",
            "Epoch 896/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0853 - acc: 0.8895 - val_loss: 0.0816 - val_acc: 0.8950\n",
            "Epoch 897/1000\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0834 - acc: 0.8895 - val_loss: 0.0803 - val_acc: 0.8950\n",
            "Epoch 898/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0844 - acc: 0.8840 - val_loss: 0.0802 - val_acc: 0.9006\n",
            "Epoch 899/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0860 - acc: 0.8895 - val_loss: 0.0804 - val_acc: 0.9006\n",
            "Epoch 900/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0810 - acc: 0.9061 - val_loss: 0.0789 - val_acc: 0.9006\n",
            "Epoch 901/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0855 - acc: 0.8895 - val_loss: 0.0798 - val_acc: 0.9061\n",
            "Epoch 902/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0798 - acc: 0.9006 - val_loss: 0.0789 - val_acc: 0.9006\n",
            "Epoch 903/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0808 - acc: 0.9006 - val_loss: 0.0789 - val_acc: 0.9006\n",
            "Epoch 904/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0791 - acc: 0.9006 - val_loss: 0.0792 - val_acc: 0.9116\n",
            "Epoch 905/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0790 - acc: 0.9116 - val_loss: 0.0838 - val_acc: 0.8895\n",
            "Epoch 906/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0831 - acc: 0.8950 - val_loss: 0.0802 - val_acc: 0.9061\n",
            "Epoch 907/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0810 - acc: 0.9171 - val_loss: 0.0811 - val_acc: 0.8950\n",
            "Epoch 908/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0799 - acc: 0.9061 - val_loss: 0.0833 - val_acc: 0.9006\n",
            "Epoch 909/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0791 - acc: 0.9061 - val_loss: 0.0848 - val_acc: 0.8950\n",
            "Epoch 910/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0817 - acc: 0.9061 - val_loss: 0.0783 - val_acc: 0.9061\n",
            "Epoch 911/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0797 - acc: 0.9006 - val_loss: 0.0781 - val_acc: 0.9006\n",
            "Epoch 912/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0791 - acc: 0.8950 - val_loss: 0.0799 - val_acc: 0.9061\n",
            "Epoch 913/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0850 - acc: 0.8950 - val_loss: 0.0923 - val_acc: 0.8785\n",
            "Epoch 914/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0911 - acc: 0.8785 - val_loss: 0.0822 - val_acc: 0.9006\n",
            "Epoch 915/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0792 - acc: 0.9061 - val_loss: 0.0785 - val_acc: 0.9006\n",
            "Epoch 916/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0813 - acc: 0.8895 - val_loss: 0.0831 - val_acc: 0.8895\n",
            "Epoch 917/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0831 - acc: 0.8950 - val_loss: 0.0899 - val_acc: 0.8729\n",
            "Epoch 918/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0873 - acc: 0.8785 - val_loss: 0.0912 - val_acc: 0.8785\n",
            "Epoch 919/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0959 - acc: 0.8674 - val_loss: 0.0807 - val_acc: 0.9061\n",
            "Epoch 920/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0874 - acc: 0.8895 - val_loss: 0.0832 - val_acc: 0.8950\n",
            "Epoch 921/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0771 - acc: 0.9061 - val_loss: 0.0833 - val_acc: 0.8895\n",
            "Epoch 922/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0841 - acc: 0.8895 - val_loss: 0.0784 - val_acc: 0.9116\n",
            "Epoch 923/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0782 - acc: 0.8950 - val_loss: 0.0793 - val_acc: 0.9061\n",
            "Epoch 924/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0828 - acc: 0.8895 - val_loss: 0.0788 - val_acc: 0.9061\n",
            "Epoch 925/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0801 - acc: 0.9006 - val_loss: 0.0789 - val_acc: 0.9006\n",
            "Epoch 926/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0817 - acc: 0.8895 - val_loss: 0.0777 - val_acc: 0.9061\n",
            "Epoch 927/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0818 - acc: 0.8895 - val_loss: 0.0810 - val_acc: 0.9061\n",
            "Epoch 928/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0827 - acc: 0.9061 - val_loss: 0.0781 - val_acc: 0.9006\n",
            "Epoch 929/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0787 - acc: 0.9006 - val_loss: 0.0779 - val_acc: 0.9006\n",
            "Epoch 930/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0816 - acc: 0.8950 - val_loss: 0.0822 - val_acc: 0.8895\n",
            "Epoch 931/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0794 - acc: 0.9006 - val_loss: 0.0838 - val_acc: 0.9006\n",
            "Epoch 932/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0857 - acc: 0.8950 - val_loss: 0.0857 - val_acc: 0.8950\n",
            "Epoch 933/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0797 - acc: 0.8895 - val_loss: 0.0792 - val_acc: 0.9061\n",
            "Epoch 934/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0877 - acc: 0.8895 - val_loss: 0.0806 - val_acc: 0.9006\n",
            "Epoch 935/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.8895 - val_loss: 0.0842 - val_acc: 0.8895\n",
            "Epoch 936/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - acc: 0.9006 - val_loss: 0.0817 - val_acc: 0.9006\n",
            "Epoch 937/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0806 - acc: 0.9006 - val_loss: 0.0777 - val_acc: 0.9006\n",
            "Epoch 938/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0783 - acc: 0.9061 - val_loss: 0.0793 - val_acc: 0.8950\n",
            "Epoch 939/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.8950 - val_loss: 0.0792 - val_acc: 0.9061\n",
            "Epoch 940/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - acc: 0.8950 - val_loss: 0.0795 - val_acc: 0.9061\n",
            "Epoch 941/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0896 - acc: 0.8785 - val_loss: 0.0848 - val_acc: 0.8950\n",
            "Epoch 942/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0908 - acc: 0.8729 - val_loss: 0.0783 - val_acc: 0.9061\n",
            "Epoch 943/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - acc: 0.8840 - val_loss: 0.0785 - val_acc: 0.9061\n",
            "Epoch 944/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - acc: 0.8895 - val_loss: 0.0800 - val_acc: 0.9061\n",
            "Epoch 945/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0832 - acc: 0.9006 - val_loss: 0.0903 - val_acc: 0.8785\n",
            "Epoch 946/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0829 - acc: 0.8840 - val_loss: 0.0795 - val_acc: 0.9061\n",
            "Epoch 947/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0870 - acc: 0.8674 - val_loss: 0.0777 - val_acc: 0.9116\n",
            "Epoch 948/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0804 - acc: 0.9061 - val_loss: 0.0830 - val_acc: 0.8895\n",
            "Epoch 949/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0853 - acc: 0.8895 - val_loss: 0.0874 - val_acc: 0.8674\n",
            "Epoch 950/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0887 - acc: 0.8840 - val_loss: 0.0777 - val_acc: 0.9116\n",
            "Epoch 951/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0814 - acc: 0.9061 - val_loss: 0.0770 - val_acc: 0.9061\n",
            "Epoch 952/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0812 - acc: 0.8895 - val_loss: 0.0898 - val_acc: 0.8674\n",
            "Epoch 953/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0900 - acc: 0.8674 - val_loss: 0.0843 - val_acc: 0.8950\n",
            "Epoch 954/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0798 - acc: 0.8950 - val_loss: 0.0774 - val_acc: 0.9116\n",
            "Epoch 955/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0779 - acc: 0.9006 - val_loss: 0.0769 - val_acc: 0.9061\n",
            "Epoch 956/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0794 - acc: 0.9006 - val_loss: 0.0778 - val_acc: 0.9006\n",
            "Epoch 957/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0778 - acc: 0.9006 - val_loss: 0.0793 - val_acc: 0.9061\n",
            "Epoch 958/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0787 - acc: 0.9061 - val_loss: 0.0778 - val_acc: 0.9006\n",
            "Epoch 959/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0817 - acc: 0.8950 - val_loss: 0.0811 - val_acc: 0.8895\n",
            "Epoch 960/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0831 - acc: 0.9006 - val_loss: 0.0776 - val_acc: 0.9006\n",
            "Epoch 961/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0888 - acc: 0.9006 - val_loss: 0.0772 - val_acc: 0.9006\n",
            "Epoch 962/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0890 - acc: 0.8729 - val_loss: 0.0843 - val_acc: 0.8895\n",
            "Epoch 963/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0825 - acc: 0.8950 - val_loss: 0.0782 - val_acc: 0.9116\n",
            "Epoch 964/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0793 - acc: 0.9061 - val_loss: 0.0771 - val_acc: 0.9171\n",
            "Epoch 965/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.9006 - val_loss: 0.0770 - val_acc: 0.9116\n",
            "Epoch 966/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0793 - acc: 0.9006 - val_loss: 0.0807 - val_acc: 0.8950\n",
            "Epoch 967/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0805 - acc: 0.8950 - val_loss: 0.0792 - val_acc: 0.9061\n",
            "Epoch 968/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0822 - acc: 0.8895 - val_loss: 0.0778 - val_acc: 0.9116\n",
            "Epoch 969/1000\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 0.0848 - acc: 0.9006 - val_loss: 0.0776 - val_acc: 0.9061\n",
            "Epoch 970/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0824 - acc: 0.9006 - val_loss: 0.0851 - val_acc: 0.8950\n",
            "Epoch 971/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0829 - acc: 0.9061 - val_loss: 0.0858 - val_acc: 0.8785\n",
            "Epoch 972/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0950 - acc: 0.8785 - val_loss: 0.0834 - val_acc: 0.8950\n",
            "Epoch 973/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0849 - acc: 0.8950 - val_loss: 0.0790 - val_acc: 0.9116\n",
            "Epoch 974/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0803 - acc: 0.9006 - val_loss: 0.0816 - val_acc: 0.9006\n",
            "Epoch 975/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0878 - acc: 0.8840 - val_loss: 0.0767 - val_acc: 0.9061\n",
            "Epoch 976/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0774 - acc: 0.9006 - val_loss: 0.0764 - val_acc: 0.9006\n",
            "Epoch 977/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0788 - acc: 0.9006 - val_loss: 0.0765 - val_acc: 0.9006\n",
            "Epoch 978/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0798 - acc: 0.8950 - val_loss: 0.0803 - val_acc: 0.8950\n",
            "Epoch 979/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0786 - acc: 0.9006 - val_loss: 0.0798 - val_acc: 0.9006\n",
            "Epoch 980/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0797 - acc: 0.9171 - val_loss: 0.0829 - val_acc: 0.8895\n",
            "Epoch 981/1000\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0873 - acc: 0.8840 - val_loss: 0.0782 - val_acc: 0.9116\n",
            "Epoch 982/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0757 - acc: 0.9061 - val_loss: 0.0830 - val_acc: 0.8895\n",
            "Epoch 983/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0811 - acc: 0.8895 - val_loss: 0.0766 - val_acc: 0.9116\n",
            "Epoch 984/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0800 - acc: 0.9006 - val_loss: 0.0776 - val_acc: 0.9061\n",
            "Epoch 985/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0941 - acc: 0.8674 - val_loss: 0.0765 - val_acc: 0.9006\n",
            "Epoch 986/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0961 - acc: 0.8564 - val_loss: 0.1041 - val_acc: 0.8508\n",
            "Epoch 987/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1008 - acc: 0.8453 - val_loss: 0.0957 - val_acc: 0.8674\n",
            "Epoch 988/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0831 - acc: 0.9006 - val_loss: 0.0782 - val_acc: 0.9116\n",
            "Epoch 989/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0771 - acc: 0.8895 - val_loss: 0.0805 - val_acc: 0.9006\n",
            "Epoch 990/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0754 - acc: 0.9116 - val_loss: 0.0883 - val_acc: 0.8840\n",
            "Epoch 991/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0872 - acc: 0.8895 - val_loss: 0.0774 - val_acc: 0.9061\n",
            "Epoch 992/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0883 - acc: 0.8729 - val_loss: 0.0773 - val_acc: 0.9061\n",
            "Epoch 993/1000\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0883 - acc: 0.8895 - val_loss: 0.0941 - val_acc: 0.8729\n",
            "Epoch 994/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.1024 - acc: 0.8674 - val_loss: 0.1011 - val_acc: 0.8619\n",
            "Epoch 995/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0867 - acc: 0.9006 - val_loss: 0.0978 - val_acc: 0.8674\n",
            "Epoch 996/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0894 - acc: 0.8785 - val_loss: 0.0800 - val_acc: 0.8950\n",
            "Epoch 997/1000\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0798 - acc: 0.9061 - val_loss: 0.0762 - val_acc: 0.9061\n",
            "Epoch 998/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0801 - acc: 0.8950 - val_loss: 0.0780 - val_acc: 0.9006\n",
            "Epoch 999/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0847 - acc: 0.9006 - val_loss: 0.0773 - val_acc: 0.9061\n",
            "Epoch 1000/1000\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0802 - acc: 0.9061 - val_loss: 0.0773 - val_acc: 0.9061\n"
          ]
        }
      ],
      "source": [
        "# start the model training\n",
        "output = []\n",
        "early = EarlyStopping(monitor='val_acc', patience=400, mode='auto')\n",
        "checkpoint = ModelCheckpoint(\"heart_disease_best_model.hdf5\", monitor='val_acc', verbose=0, save_best_only=True, mode='auto', save_freq='epoch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.01, patience=100, verbose=1, mode='auto', min_lr=0.001)\n",
        "callbacks_list = [early]\n",
        "\n",
        "output = model.fit(x_train, y_train,validation_data=(x_val,y_val), epochs=1000, batch_size=16, verbose=1, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 447,
      "metadata": {
        "id": "7sYpy54d2t4H"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### 12. What does the plot generated by this code represent?\n",
        "\n",
        "plt.plot(output.history['acc'])\n",
        "plt.plot(output.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 448,
      "metadata": {
        "id": "yIrcCZ8P2t4N"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### 13. Plot code for the model loss. You can refer to the plot code for model accuracy above.\n",
        "\n",
        "plt.plot(output.history['loss'])\n",
        "plt.plot(output.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train loss', 'val loss'], loc='upper left')\n",
        "#plt.savefig('Accuracy.png',dpi=100) #to save the image\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 449,
      "metadata": {
        "id": "KTWzuJM12t4A",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 1ms/step - loss: 0.0773 - acc: 0.9061\n",
            "\n",
            "acc: 90.61%\n",
            "loss: 0.08\n"
          ]
        }
      ],
      "source": [
        "### 14. What is the purpose of evaluating the model on the test dataset?\n",
        "\n",
        "#model.load_weights(model_loc+\"heart_disease_best_model.hdf5\")\n",
        "scores = model.evaluate(x_test, y_test)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "# print(\"\\n%s: %.2f%%\" % (model.metrics_names[0], scores[0]))\n",
        "print(\"loss:\", round(scores[0],2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 450,
      "metadata": {
        "id": "NNYy0CRt2t4R"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 1ms/step\n",
            "\u001b[30mNo: 1 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 2 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 3 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 4 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 5 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 6 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 7 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 8 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 9 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 10 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 11 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 12 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 13 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 14 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 15 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 16 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 17 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 18 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 19 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 20 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 21 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 22 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 23 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 24 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 25 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 26 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 27 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 28 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 29 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 30 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 31 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 32 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 33 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 34 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 35 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 36 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 37 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 38 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 39 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 40 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 41 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 42 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 43 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 44 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 45 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 46 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 47 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 48 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 49 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 50 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 51 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 52 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 53 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 54 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 55 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 56 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 57 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 58 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 59 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 60 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 61 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 62 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 63 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 64 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 65 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 66 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 67 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 68 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 69 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 70 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 71 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 72 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 73 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 74 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 75 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 76 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 77 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 78 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 79 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 80 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 81 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 82 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 83 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 84 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 85 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 86 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 87 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 88 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 89 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 90 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 91 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 92 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 93 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 94 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 95 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 96 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 97 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 98 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 99 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 100 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 101 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 102 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 103 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 104 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 105 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 106 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 107 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 108 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 109 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 110 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 111 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 112 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 113 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 114 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 115 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 116 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 117 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 118 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 119 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 120 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 121 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 122 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 123 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 124 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 125 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 126 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 127 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 128 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 129 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 130 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 131 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 132 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 133 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 134 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 135 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 136 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 137 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 138 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 139 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 140 Actual: [1.]  Predicted: [0]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 141 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 142 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 143 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 144 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 145 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 146 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 147 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 148 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 149 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 150 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 151 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 152 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 153 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 154 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 155 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 156 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 157 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 158 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 159 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 160 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 161 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 162 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 163 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 164 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 165 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 166 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 167 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 168 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 169 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 170 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 171 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 172 Actual: [0.]  Predicted: [1]  Result: \u001b[91mFail\n",
            "\u001b[30mNo: 173 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 174 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 175 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 176 Actual: [0.]  Predicted: [0] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 177 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 178 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 179 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 180 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mNo: 181 Actual: [1.]  Predicted: [1] Result: \u001b[92mPass\n",
            "\u001b[30mRight Prediction : 164 Wrong Prediction : 17\n"
          ]
        }
      ],
      "source": [
        "#Display detailed prediction\n",
        "pred = model.predict(x_test)\n",
        "y = np.round(pred).astype(\"int16\")\n",
        "idx = 0\n",
        "ps = 0\n",
        "fl = 0\n",
        "for x in pred:\n",
        "    if y_test[idx]==y[idx]:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\"Result: \\033[92mPass\")\n",
        "        ps = ps+1\n",
        "    else:\n",
        "        print(\"\\033[30mNo:\",idx+1,\"Actual:\",y_test[idx],\" Predicted:\",y[idx],\" Result: \\033[91mFail\")\n",
        "        fl = fl+1\n",
        "    idx = idx + 1\n",
        "print(\"\\033[30mRight Prediction :\",ps, \"Wrong Prediction :\",fl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 451,
      "metadata": {
        "id": "pHQBXNX5aYcn"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.88      0.89        80\n",
            "           1       0.90      0.93      0.92       101\n",
            "\n",
            "    accuracy                           0.91       181\n",
            "   macro avg       0.91      0.90      0.90       181\n",
            "weighted avg       0.91      0.91      0.91       181\n",
            "\n"
          ]
        }
      ],
      "source": [
        "### 15. What is Confusion Matrix and why you need it? Explain TP, FP, FN, TN.\n",
        "### 16. Explain the classification report produce.\n",
        "\n",
        "y_pred = y\n",
        "y_true = y_test\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1])\n",
        "#cm = confusion_matrix(y_true, y_pred, labels=labels.astype('int'))\n",
        "f, ax=plt.subplots(figsize=(5,5))\n",
        "sns.heatmap(cm,annot=True,linewidths=1.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
        "plt.xlabel(\"y_pred\")\n",
        "plt.ylabel(\"y_true\")\n",
        "plt.show()\n",
        "print()\n",
        "print(classification_report(y_true, y_pred, labels=[0,1]))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
